{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2175a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing needed packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80a00a",
   "metadata": {},
   "source": [
    "# Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbd1b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the data into a dataframe from the csv file and viewing the first 5 \n",
    "\n",
    "stroke_df = pd.read_csv('Datasets/Stroke/healthcare-dataset-stroke-data.csv')\n",
    "stroke_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0070ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid potential baises from the data such as gender,glucose level, and bmi \n",
    "# and unneeded data such as identifications\n",
    "\n",
    "stroke_df = stroke_df.drop(['id'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e428d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at where there are null repsonses in the dataframe\n",
    "\n",
    "stroke_df.isnull().sum()\n",
    "\n",
    "#Getting rid of the row of the null responses from the dataframe,\n",
    "            #since we are going to keep the columns that have the Null reponses \n",
    "\n",
    "stroke_df = stroke_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9f59e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4909.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.865374</td>\n",
       "      <td>0.091872</td>\n",
       "      <td>0.049501</td>\n",
       "      <td>105.305150</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>0.042575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.555115</td>\n",
       "      <td>0.288875</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>44.424341</td>\n",
       "      <td>7.854067</td>\n",
       "      <td>0.201917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.120000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.070000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.680000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.570000</td>\n",
       "      <td>33.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>97.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  hypertension  heart_disease  avg_glucose_level  \\\n",
       "count  4909.000000   4909.000000    4909.000000        4909.000000   \n",
       "mean     42.865374      0.091872       0.049501         105.305150   \n",
       "std      22.555115      0.288875       0.216934          44.424341   \n",
       "min       0.080000      0.000000       0.000000          55.120000   \n",
       "25%      25.000000      0.000000       0.000000          77.070000   \n",
       "50%      44.000000      0.000000       0.000000          91.680000   \n",
       "75%      60.000000      0.000000       0.000000         113.570000   \n",
       "max      82.000000      1.000000       1.000000         271.740000   \n",
       "\n",
       "               bmi       stroke  \n",
       "count  4909.000000  4909.000000  \n",
       "mean     28.893237     0.042575  \n",
       "std       7.854067     0.201917  \n",
       "min      10.300000     0.000000  \n",
       "25%      23.500000     0.000000  \n",
       "50%      28.100000     0.000000  \n",
       "75%      33.100000     0.000000  \n",
       "max      97.600000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a simple analysis of qualitative data of the dataset  \n",
    "# focusing on the realtativly weight of how many people gotten a stroke\n",
    "\n",
    "stroke_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd48efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the unique values of the dataset to get an insight of what the values are - checking if there's any\n",
    "# incorrect inputs in our dataset\n",
    "# Also getting the information of the type of data, columns, and null\n",
    "\n",
    "def unique_values_in_columns(dataframe):\n",
    "    unique_values_dict = {}\n",
    "    \n",
    "    for column in dataframe.columns:\n",
    "        unique_values_dict[column] = dataframe[column].unique().tolist()\n",
    "    \n",
    "    return unique_values_dict, dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f071f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4909 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             4909 non-null   object \n",
      " 1   age                4909 non-null   float64\n",
      " 2   hypertension       4909 non-null   int64  \n",
      " 3   heart_disease      4909 non-null   int64  \n",
      " 4   ever_married       4909 non-null   object \n",
      " 5   work_type          4909 non-null   object \n",
      " 6   Residence_type     4909 non-null   object \n",
      " 7   avg_glucose_level  4909 non-null   float64\n",
      " 8   bmi                4909 non-null   float64\n",
      " 9   smoking_status     4909 non-null   object \n",
      " 10  stroke             4909 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 460.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'gender': ['Male', 'Female', 'Other'],\n",
       "  'age': [67.0,\n",
       "   80.0,\n",
       "   49.0,\n",
       "   79.0,\n",
       "   81.0,\n",
       "   74.0,\n",
       "   69.0,\n",
       "   78.0,\n",
       "   61.0,\n",
       "   54.0,\n",
       "   50.0,\n",
       "   64.0,\n",
       "   75.0,\n",
       "   60.0,\n",
       "   71.0,\n",
       "   52.0,\n",
       "   82.0,\n",
       "   65.0,\n",
       "   57.0,\n",
       "   42.0,\n",
       "   48.0,\n",
       "   72.0,\n",
       "   58.0,\n",
       "   76.0,\n",
       "   39.0,\n",
       "   77.0,\n",
       "   63.0,\n",
       "   73.0,\n",
       "   56.0,\n",
       "   45.0,\n",
       "   70.0,\n",
       "   59.0,\n",
       "   66.0,\n",
       "   43.0,\n",
       "   68.0,\n",
       "   47.0,\n",
       "   53.0,\n",
       "   38.0,\n",
       "   55.0,\n",
       "   46.0,\n",
       "   32.0,\n",
       "   51.0,\n",
       "   14.0,\n",
       "   3.0,\n",
       "   8.0,\n",
       "   37.0,\n",
       "   40.0,\n",
       "   35.0,\n",
       "   20.0,\n",
       "   44.0,\n",
       "   25.0,\n",
       "   27.0,\n",
       "   23.0,\n",
       "   17.0,\n",
       "   13.0,\n",
       "   4.0,\n",
       "   16.0,\n",
       "   22.0,\n",
       "   30.0,\n",
       "   29.0,\n",
       "   11.0,\n",
       "   21.0,\n",
       "   18.0,\n",
       "   33.0,\n",
       "   24.0,\n",
       "   36.0,\n",
       "   0.64,\n",
       "   34.0,\n",
       "   41.0,\n",
       "   0.88,\n",
       "   5.0,\n",
       "   26.0,\n",
       "   31.0,\n",
       "   7.0,\n",
       "   12.0,\n",
       "   62.0,\n",
       "   2.0,\n",
       "   9.0,\n",
       "   15.0,\n",
       "   28.0,\n",
       "   10.0,\n",
       "   1.8,\n",
       "   0.32,\n",
       "   1.08,\n",
       "   19.0,\n",
       "   6.0,\n",
       "   1.16,\n",
       "   1.0,\n",
       "   1.4,\n",
       "   1.72,\n",
       "   0.24,\n",
       "   1.64,\n",
       "   1.56,\n",
       "   0.72,\n",
       "   1.88,\n",
       "   1.24,\n",
       "   0.8,\n",
       "   0.4,\n",
       "   0.08,\n",
       "   1.48,\n",
       "   0.56,\n",
       "   1.32,\n",
       "   0.16,\n",
       "   0.48],\n",
       "  'hypertension': [0, 1],\n",
       "  'heart_disease': [1, 0],\n",
       "  'ever_married': ['Yes', 'No'],\n",
       "  'work_type': ['Private',\n",
       "   'Self-employed',\n",
       "   'Govt_job',\n",
       "   'children',\n",
       "   'Never_worked'],\n",
       "  'Residence_type': ['Urban', 'Rural'],\n",
       "  'avg_glucose_level': [228.69,\n",
       "   105.92,\n",
       "   171.23,\n",
       "   174.12,\n",
       "   186.21,\n",
       "   70.09,\n",
       "   94.39,\n",
       "   58.57,\n",
       "   80.43,\n",
       "   120.46,\n",
       "   104.51,\n",
       "   214.09,\n",
       "   167.41,\n",
       "   191.61,\n",
       "   221.29,\n",
       "   89.22,\n",
       "   193.94,\n",
       "   233.29,\n",
       "   228.7,\n",
       "   208.3,\n",
       "   102.87,\n",
       "   104.12,\n",
       "   100.98,\n",
       "   195.23,\n",
       "   212.08,\n",
       "   83.41,\n",
       "   196.92,\n",
       "   252.72,\n",
       "   84.2,\n",
       "   84.03,\n",
       "   219.72,\n",
       "   74.63,\n",
       "   92.62,\n",
       "   60.91,\n",
       "   78.03,\n",
       "   71.22,\n",
       "   144.9,\n",
       "   213.03,\n",
       "   243.58,\n",
       "   107.26,\n",
       "   99.33,\n",
       "   58.09,\n",
       "   127.29,\n",
       "   124.13,\n",
       "   196.71,\n",
       "   59.32,\n",
       "   194.99,\n",
       "   180.93,\n",
       "   185.17,\n",
       "   74.9,\n",
       "   61.94,\n",
       "   93.72,\n",
       "   113.01,\n",
       "   221.58,\n",
       "   104.47,\n",
       "   86.23,\n",
       "   72.67,\n",
       "   179.12,\n",
       "   116.55,\n",
       "   228.56,\n",
       "   96.59,\n",
       "   66.72,\n",
       "   240.09,\n",
       "   110.85,\n",
       "   143.43,\n",
       "   96.16,\n",
       "   88.92,\n",
       "   79.79,\n",
       "   96.97,\n",
       "   111.81,\n",
       "   59.35,\n",
       "   86.94,\n",
       "   98.55,\n",
       "   226.98,\n",
       "   72.81,\n",
       "   68.02,\n",
       "   68.56,\n",
       "   64.14,\n",
       "   235.63,\n",
       "   76.34,\n",
       "   240.59,\n",
       "   78.92,\n",
       "   82.81,\n",
       "   74.1,\n",
       "   190.32,\n",
       "   231.61,\n",
       "   78.7,\n",
       "   110.52,\n",
       "   73.18,\n",
       "   191.82,\n",
       "   93.05,\n",
       "   64.17,\n",
       "   129.98,\n",
       "   68.53,\n",
       "   224.1,\n",
       "   82.1,\n",
       "   216.94,\n",
       "   76.11,\n",
       "   72.96,\n",
       "   82.28,\n",
       "   105.22,\n",
       "   59.86,\n",
       "   62.55,\n",
       "   259.63,\n",
       "   249.31,\n",
       "   131.41,\n",
       "   73.54,\n",
       "   200.59,\n",
       "   190.14,\n",
       "   130.54,\n",
       "   182.99,\n",
       "   206.09,\n",
       "   263.32,\n",
       "   140.1,\n",
       "   207.28,\n",
       "   194.37,\n",
       "   199.2,\n",
       "   103.68,\n",
       "   116.44,\n",
       "   70.28,\n",
       "   72.17,\n",
       "   221.79,\n",
       "   151.16,\n",
       "   67.29,\n",
       "   67.41,\n",
       "   239.07,\n",
       "   223.83,\n",
       "   76.57,\n",
       "   77.82,\n",
       "   92.98,\n",
       "   231.56,\n",
       "   102.16,\n",
       "   221.89,\n",
       "   195.71,\n",
       "   74.02,\n",
       "   203.87,\n",
       "   89.13,\n",
       "   133.19,\n",
       "   162.23,\n",
       "   98.02,\n",
       "   91.54,\n",
       "   97.43,\n",
       "   91.02,\n",
       "   185.49,\n",
       "   64.44,\n",
       "   56.11,\n",
       "   213.22,\n",
       "   78.18,\n",
       "   111.04,\n",
       "   76.13,\n",
       "   112.24,\n",
       "   137.3,\n",
       "   116.69,\n",
       "   215.94,\n",
       "   86.62,\n",
       "   205.77,\n",
       "   112.16,\n",
       "   118.03,\n",
       "   271.74,\n",
       "   97.92,\n",
       "   200.62,\n",
       "   242.52,\n",
       "   93.81,\n",
       "   74.96,\n",
       "   175.29,\n",
       "   90.0,\n",
       "   109.47,\n",
       "   87.85,\n",
       "   106.74,\n",
       "   80.13,\n",
       "   90.19,\n",
       "   134.8,\n",
       "   106.58,\n",
       "   83.24,\n",
       "   103.43,\n",
       "   208.65,\n",
       "   74.11,\n",
       "   95.84,\n",
       "   205.33,\n",
       "   116.1,\n",
       "   210.4,\n",
       "   219.73,\n",
       "   250.89,\n",
       "   72.73,\n",
       "   205.35,\n",
       "   70.3,\n",
       "   104.86,\n",
       "   216.58,\n",
       "   184.4,\n",
       "   97.76,\n",
       "   66.03,\n",
       "   81.95,\n",
       "   97.73,\n",
       "   70.94,\n",
       "   199.84,\n",
       "   218.46,\n",
       "   211.06,\n",
       "   86.3,\n",
       "   162.14,\n",
       "   88.2,\n",
       "   91.92,\n",
       "   76.46,\n",
       "   197.28,\n",
       "   233.94,\n",
       "   247.51,\n",
       "   84.96,\n",
       "   57.93,\n",
       "   78.8,\n",
       "   78.81,\n",
       "   95.12,\n",
       "   87.96,\n",
       "   110.89,\n",
       "   69.04,\n",
       "   161.28,\n",
       "   210.95,\n",
       "   77.59,\n",
       "   243.53,\n",
       "   77.67,\n",
       "   205.84,\n",
       "   77.08,\n",
       "   57.08,\n",
       "   162.96,\n",
       "   73.5,\n",
       "   95.04,\n",
       "   85.37,\n",
       "   84.62,\n",
       "   82.67,\n",
       "   57.33,\n",
       "   67.84,\n",
       "   75.7,\n",
       "   129.54,\n",
       "   60.22,\n",
       "   198.21,\n",
       "   109.82,\n",
       "   60.84,\n",
       "   94.61,\n",
       "   97.49,\n",
       "   206.72,\n",
       "   214.45,\n",
       "   82.9,\n",
       "   103.26,\n",
       "   55.78,\n",
       "   73.74,\n",
       "   149.75,\n",
       "   82.34,\n",
       "   62.6,\n",
       "   94.09,\n",
       "   55.42,\n",
       "   82.18,\n",
       "   117.92,\n",
       "   114.84,\n",
       "   79.17,\n",
       "   110.63,\n",
       "   190.7,\n",
       "   79.81,\n",
       "   113.63,\n",
       "   141.24,\n",
       "   56.96,\n",
       "   203.04,\n",
       "   94.3,\n",
       "   81.51,\n",
       "   137.74,\n",
       "   81.84,\n",
       "   242.3,\n",
       "   102.64,\n",
       "   146.01,\n",
       "   75.42,\n",
       "   220.49,\n",
       "   61.45,\n",
       "   88.19,\n",
       "   115.22,\n",
       "   97.93,\n",
       "   85.6,\n",
       "   79.83,\n",
       "   62.2,\n",
       "   69.15,\n",
       "   127.71,\n",
       "   216.7,\n",
       "   71.89,\n",
       "   103.56,\n",
       "   79.03,\n",
       "   69.94,\n",
       "   90.12,\n",
       "   95.1,\n",
       "   234.58,\n",
       "   235.85,\n",
       "   78.05,\n",
       "   89.44,\n",
       "   111.38,\n",
       "   243.5,\n",
       "   182.2,\n",
       "   229.92,\n",
       "   82.24,\n",
       "   89.84,\n",
       "   90.69,\n",
       "   84.38,\n",
       "   215.6,\n",
       "   91.61,\n",
       "   138.16,\n",
       "   75.23,\n",
       "   75.18,\n",
       "   239.64,\n",
       "   58.95,\n",
       "   99.92,\n",
       "   116.23,\n",
       "   118.82,\n",
       "   66.3,\n",
       "   101.41,\n",
       "   200.28,\n",
       "   136.8,\n",
       "   96.57,\n",
       "   66.42,\n",
       "   98.09,\n",
       "   205.23,\n",
       "   86.78,\n",
       "   126.82,\n",
       "   78.4,\n",
       "   63.69,\n",
       "   89.86,\n",
       "   110.99,\n",
       "   83.82,\n",
       "   137.96,\n",
       "   210.78,\n",
       "   118.89,\n",
       "   72.55,\n",
       "   107.41,\n",
       "   93.25,\n",
       "   74.91,\n",
       "   80.05,\n",
       "   99.8,\n",
       "   91.97,\n",
       "   64.4,\n",
       "   73.02,\n",
       "   88.11,\n",
       "   138.29,\n",
       "   72.36,\n",
       "   68.76,\n",
       "   106.22,\n",
       "   101.52,\n",
       "   109.51,\n",
       "   85.84,\n",
       "   110.15,\n",
       "   91.72,\n",
       "   251.6,\n",
       "   123.1,\n",
       "   97.4,\n",
       "   68.34,\n",
       "   80.81,\n",
       "   120.31,\n",
       "   83.51,\n",
       "   74.09,\n",
       "   91.6,\n",
       "   87.52,\n",
       "   213.37,\n",
       "   75.39,\n",
       "   122.41,\n",
       "   223.36,\n",
       "   84.59,\n",
       "   70.16,\n",
       "   107.52,\n",
       "   80.88,\n",
       "   93.48,\n",
       "   70.21,\n",
       "   86.67,\n",
       "   101.37,\n",
       "   70.31,\n",
       "   64.06,\n",
       "   178.29,\n",
       "   81.6,\n",
       "   147.48,\n",
       "   86.86,\n",
       "   71.16,\n",
       "   73.2,\n",
       "   203.81,\n",
       "   82.0,\n",
       "   97.55,\n",
       "   94.29,\n",
       "   75.22,\n",
       "   90.07,\n",
       "   73.73,\n",
       "   79.58,\n",
       "   77.88,\n",
       "   205.26,\n",
       "   58.63,\n",
       "   139.9,\n",
       "   211.03,\n",
       "   72.79,\n",
       "   91.65,\n",
       "   225.47,\n",
       "   94.48,\n",
       "   180.63,\n",
       "   92.48,\n",
       "   116.66,\n",
       "   112.09,\n",
       "   130.34,\n",
       "   82.59,\n",
       "   123.87,\n",
       "   98.7,\n",
       "   227.1,\n",
       "   55.39,\n",
       "   66.07,\n",
       "   104.21,\n",
       "   145.15,\n",
       "   68.19,\n",
       "   97.53,\n",
       "   122.31,\n",
       "   86.46,\n",
       "   112.06,\n",
       "   92.14,\n",
       "   201.76,\n",
       "   74.44,\n",
       "   95.93,\n",
       "   87.51,\n",
       "   72.35,\n",
       "   113.47,\n",
       "   103.78,\n",
       "   115.43,\n",
       "   95.59,\n",
       "   170.05,\n",
       "   217.3,\n",
       "   196.01,\n",
       "   92.21,\n",
       "   100.09,\n",
       "   93.88,\n",
       "   75.05,\n",
       "   70.08,\n",
       "   74.2,\n",
       "   69.01,\n",
       "   96.17,\n",
       "   87.24,\n",
       "   82.58,\n",
       "   96.88,\n",
       "   73.32,\n",
       "   94.59,\n",
       "   132.08,\n",
       "   98.99,\n",
       "   104.48,\n",
       "   98.01,\n",
       "   79.14,\n",
       "   89.32,\n",
       "   65.24,\n",
       "   80.98,\n",
       "   186.17,\n",
       "   69.24,\n",
       "   111.19,\n",
       "   93.28,\n",
       "   122.19,\n",
       "   129.53,\n",
       "   114.53,\n",
       "   93.73,\n",
       "   77.49,\n",
       "   65.38,\n",
       "   94.18,\n",
       "   118.7,\n",
       "   96.29,\n",
       "   74.64,\n",
       "   96.99,\n",
       "   100.61,\n",
       "   97.08,\n",
       "   84.79,\n",
       "   78.75,\n",
       "   82.93,\n",
       "   88.78,\n",
       "   122.1,\n",
       "   74.81,\n",
       "   183.45,\n",
       "   114.94,\n",
       "   104.38,\n",
       "   102.91,\n",
       "   108.79,\n",
       "   73.31,\n",
       "   68.52,\n",
       "   70.92,\n",
       "   86.11,\n",
       "   129.16,\n",
       "   113.85,\n",
       "   79.35,\n",
       "   80.79,\n",
       "   114.01,\n",
       "   93.74,\n",
       "   90.65,\n",
       "   98.41,\n",
       "   127.18,\n",
       "   138.06,\n",
       "   105.61,\n",
       "   155.43,\n",
       "   80.83,\n",
       "   80.19,\n",
       "   60.34,\n",
       "   79.3,\n",
       "   98.44,\n",
       "   210.48,\n",
       "   70.34,\n",
       "   122.22,\n",
       "   75.29,\n",
       "   100.35,\n",
       "   193.83,\n",
       "   126.96,\n",
       "   183.34,\n",
       "   247.69,\n",
       "   76.2,\n",
       "   71.43,\n",
       "   93.36,\n",
       "   61.29,\n",
       "   103.62,\n",
       "   100.52,\n",
       "   191.47,\n",
       "   67.06,\n",
       "   144.1,\n",
       "   58.26,\n",
       "   239.82,\n",
       "   73.71,\n",
       "   88.53,\n",
       "   114.79,\n",
       "   113.8,\n",
       "   71.91,\n",
       "   65.3,\n",
       "   189.57,\n",
       "   114.25,\n",
       "   81.26,\n",
       "   87.88,\n",
       "   112.17,\n",
       "   99.97,\n",
       "   207.58,\n",
       "   109.16,\n",
       "   74.46,\n",
       "   118.51,\n",
       "   107.47,\n",
       "   182.86,\n",
       "   59.17,\n",
       "   215.64,\n",
       "   163.7,\n",
       "   196.36,\n",
       "   139.77,\n",
       "   141.23,\n",
       "   89.99,\n",
       "   108.53,\n",
       "   63.61,\n",
       "   85.54,\n",
       "   100.83,\n",
       "   59.82,\n",
       "   105.95,\n",
       "   188.11,\n",
       "   71.15,\n",
       "   60.53,\n",
       "   205.5,\n",
       "   204.86,\n",
       "   115.03,\n",
       "   79.87,\n",
       "   97.89,\n",
       "   125.26,\n",
       "   114.32,\n",
       "   92.23,\n",
       "   102.34,\n",
       "   144.48,\n",
       "   88.39,\n",
       "   228.08,\n",
       "   93.79,\n",
       "   147.14,\n",
       "   106.43,\n",
       "   88.04,\n",
       "   92.2,\n",
       "   219.53,\n",
       "   75.56,\n",
       "   158.31,\n",
       "   111.43,\n",
       "   219.97,\n",
       "   148.91,\n",
       "   69.4,\n",
       "   58.37,\n",
       "   71.2,\n",
       "   101.5,\n",
       "   92.04,\n",
       "   73.0,\n",
       "   111.15,\n",
       "   58.65,\n",
       "   100.54,\n",
       "   111.73,\n",
       "   97.78,\n",
       "   85.79,\n",
       "   98.54,\n",
       "   94.62,\n",
       "   112.43,\n",
       "   99.67,\n",
       "   67.39,\n",
       "   85.06,\n",
       "   214.05,\n",
       "   79.09,\n",
       "   76.36,\n",
       "   98.42,\n",
       "   82.01,\n",
       "   111.85,\n",
       "   92.39,\n",
       "   112.54,\n",
       "   63.71,\n",
       "   70.35,\n",
       "   94.65,\n",
       "   64.64,\n",
       "   57.27,\n",
       "   107.25,\n",
       "   77.12,\n",
       "   55.32,\n",
       "   69.37,\n",
       "   57.57,\n",
       "   87.43,\n",
       "   98.73,\n",
       "   81.18,\n",
       "   56.23,\n",
       "   69.61,\n",
       "   59.49,\n",
       "   100.26,\n",
       "   56.75,\n",
       "   67.81,\n",
       "   77.46,\n",
       "   76.26,\n",
       "   86.39,\n",
       "   116.38,\n",
       "   75.74,\n",
       "   149.95,\n",
       "   74.98,\n",
       "   55.25,\n",
       "   79.89,\n",
       "   130.61,\n",
       "   94.26,\n",
       "   94.34,\n",
       "   109.03,\n",
       "   81.03,\n",
       "   99.82,\n",
       "   140.08,\n",
       "   59.54,\n",
       "   80.33,\n",
       "   131.51,\n",
       "   89.21,\n",
       "   91.45,\n",
       "   90.58,\n",
       "   89.63,\n",
       "   124.06,\n",
       "   99.47,\n",
       "   88.97,\n",
       "   80.93,\n",
       "   102.07,\n",
       "   91.69,\n",
       "   200.49,\n",
       "   75.3,\n",
       "   240.71,\n",
       "   60.5,\n",
       "   131.85,\n",
       "   134.39,\n",
       "   56.18,\n",
       "   113.64,\n",
       "   156.57,\n",
       "   80.4,\n",
       "   59.26,\n",
       "   63.26,\n",
       "   86.24,\n",
       "   197.1,\n",
       "   90.9,\n",
       "   121.8,\n",
       "   77.65,\n",
       "   64.41,\n",
       "   75.19,\n",
       "   67.97,\n",
       "   119.34,\n",
       "   94.92,\n",
       "   85.02,\n",
       "   103.51,\n",
       "   114.5,\n",
       "   70.78,\n",
       "   95.01,\n",
       "   84.11,\n",
       "   78.49,\n",
       "   74.22,\n",
       "   55.34,\n",
       "   75.04,\n",
       "   109.73,\n",
       "   96.78,\n",
       "   194.62,\n",
       "   70.02,\n",
       "   222.21,\n",
       "   62.41,\n",
       "   55.83,\n",
       "   65.12,\n",
       "   73.62,\n",
       "   85.83,\n",
       "   103.86,\n",
       "   60.98,\n",
       "   82.69,\n",
       "   250.2,\n",
       "   128.97,\n",
       "   84.31,\n",
       "   74.8,\n",
       "   97.06,\n",
       "   77.54,\n",
       "   92.78,\n",
       "   173.43,\n",
       "   79.08,\n",
       "   106.18,\n",
       "   114.21,\n",
       "   91.08,\n",
       "   105.77,\n",
       "   74.88,\n",
       "   123.15,\n",
       "   184.25,\n",
       "   117.69,\n",
       "   55.26,\n",
       "   106.51,\n",
       "   55.27,\n",
       "   99.2,\n",
       "   98.92,\n",
       "   92.7,\n",
       "   106.7,\n",
       "   152.81,\n",
       "   91.0,\n",
       "   76.99,\n",
       "   254.6,\n",
       "   93.99,\n",
       "   109.68,\n",
       "   111.41,\n",
       "   65.61,\n",
       "   62.37,\n",
       "   101.28,\n",
       "   88.31,\n",
       "   103.55,\n",
       "   60.26,\n",
       "   79.39,\n",
       "   122.01,\n",
       "   78.09,\n",
       "   89.7,\n",
       "   112.64,\n",
       "   79.8,\n",
       "   82.2,\n",
       "   108.89,\n",
       "   116.14,\n",
       "   122.74,\n",
       "   94.04,\n",
       "   86.6,\n",
       "   82.32,\n",
       "   83.83,\n",
       "   106.98,\n",
       "   70.53,\n",
       "   212.01,\n",
       "   65.88,\n",
       "   106.97,\n",
       "   126.35,\n",
       "   88.66,\n",
       "   112.95,\n",
       "   81.59,\n",
       "   76.82,\n",
       "   73.75,\n",
       "   91.56,\n",
       "   104.55,\n",
       "   84.84,\n",
       "   86.06,\n",
       "   109.1,\n",
       "   68.35,\n",
       "   121.04,\n",
       "   160.83,\n",
       "   85.62,\n",
       "   74.23,\n",
       "   110.76,\n",
       "   79.44,\n",
       "   119.52,\n",
       "   90.42,\n",
       "   109.32,\n",
       "   78.16,\n",
       "   79.13,\n",
       "   84.06,\n",
       "   89.3,\n",
       "   69.21,\n",
       "   186.45,\n",
       "   58.47,\n",
       "   189.49,\n",
       "   99.6,\n",
       "   126.18,\n",
       "   186.32,\n",
       "   62.49,\n",
       "   74.51,\n",
       "   94.63,\n",
       "   91.98,\n",
       "   56.77,\n",
       "   75.87,\n",
       "   77.19,\n",
       "   135.75,\n",
       "   100.15,\n",
       "   95.08,\n",
       "   125.38,\n",
       "   111.71,\n",
       "   94.64,\n",
       "   112.96,\n",
       "   105.36,\n",
       "   84.13,\n",
       "   102.47,\n",
       "   77.04,\n",
       "   87.01,\n",
       "   56.99,\n",
       "   73.01,\n",
       "   106.35,\n",
       "   80.63,\n",
       "   103.61,\n",
       "   194.04,\n",
       "   111.99,\n",
       "   57.51,\n",
       "   68.49,\n",
       "   60.2,\n",
       "   160.0,\n",
       "   86.96,\n",
       "   237.15,\n",
       "   99.06,\n",
       "   56.31,\n",
       "   90.92,\n",
       "   104.33,\n",
       "   62.61,\n",
       "   231.19,\n",
       "   72.62,\n",
       "   81.64,\n",
       "   90.78,\n",
       "   70.71,\n",
       "   59.76,\n",
       "   63.64,\n",
       "   82.06,\n",
       "   110.91,\n",
       "   77.16,\n",
       "   69.58,\n",
       "   96.26,\n",
       "   87.27,\n",
       "   65.36,\n",
       "   89.03,\n",
       "   91.34,\n",
       "   57.82,\n",
       "   81.15,\n",
       "   115.29,\n",
       "   111.02,\n",
       "   111.61,\n",
       "   109.02,\n",
       "   207.32,\n",
       "   87.11,\n",
       "   61.68,\n",
       "   119.04,\n",
       "   86.05,\n",
       "   70.03,\n",
       "   207.64,\n",
       "   236.84,\n",
       "   78.11,\n",
       "   100.97,\n",
       "   99.21,\n",
       "   113.21,\n",
       "   92.95,\n",
       "   142.57,\n",
       "   92.87,\n",
       "   111.48,\n",
       "   123.0,\n",
       "   106.68,\n",
       "   86.4,\n",
       "   61.81,\n",
       "   128.28,\n",
       "   204.63,\n",
       "   89.98,\n",
       "   232.89,\n",
       "   98.58,\n",
       "   57.94,\n",
       "   123.21,\n",
       "   92.81,\n",
       "   85.16,\n",
       "   90.1,\n",
       "   65.15,\n",
       "   104.62,\n",
       "   113.25,\n",
       "   59.28,\n",
       "   93.07,\n",
       "   77.42,\n",
       "   73.69,\n",
       "   58.39,\n",
       "   102.05,\n",
       "   112.47,\n",
       "   72.84,\n",
       "   195.03,\n",
       "   170.95,\n",
       "   87.98,\n",
       "   65.81,\n",
       "   124.6,\n",
       "   83.65,\n",
       "   88.81,\n",
       "   86.75,\n",
       "   123.36,\n",
       "   89.68,\n",
       "   69.87,\n",
       "   109.22,\n",
       "   157.57,\n",
       "   110.73,\n",
       "   99.14,\n",
       "   59.15,\n",
       "   165.11,\n",
       "   77.44,\n",
       "   100.33,\n",
       "   148.24,\n",
       "   91.96,\n",
       "   72.93,\n",
       "   84.27,\n",
       "   124.45,\n",
       "   90.51,\n",
       "   118.87,\n",
       "   56.42,\n",
       "   73.67,\n",
       "   89.11,\n",
       "   74.04,\n",
       "   145.23,\n",
       "   100.8,\n",
       "   85.22,\n",
       "   72.49,\n",
       "   82.61,\n",
       "   72.07,\n",
       "   79.85,\n",
       "   84.86,\n",
       "   131.89,\n",
       "   89.17,\n",
       "   227.91,\n",
       "   131.77,\n",
       "   102.01,\n",
       "   128.63,\n",
       "   143.15,\n",
       "   116.67,\n",
       "   142.12,\n",
       "   100.81,\n",
       "   69.17,\n",
       "   58.38,\n",
       "   86.34,\n",
       "   95.44,\n",
       "   94.78,\n",
       "   109.59,\n",
       "   79.26,\n",
       "   78.46,\n",
       "   85.29,\n",
       "   156.18,\n",
       "   69.52,\n",
       "   65.32,\n",
       "   108.47,\n",
       "   105.63,\n",
       "   77.93,\n",
       "   95.2,\n",
       "   78.52,\n",
       "   114.89,\n",
       "   95.43,\n",
       "   84.08,\n",
       "   110.55,\n",
       "   82.21,\n",
       "   82.38,\n",
       "   93.89,\n",
       "   75.08,\n",
       "   76.72,\n",
       "   84.93,\n",
       "   76.5,\n",
       "   65.47,\n",
       "   99.16,\n",
       "   63.53,\n",
       "   78.65,\n",
       "   63.78,\n",
       "   77.52,\n",
       "   111.64,\n",
       "   97.84,\n",
       "   56.48,\n",
       "   204.5,\n",
       "   96.02,\n",
       "   206.25,\n",
       "   115.52,\n",
       "   60.69,\n",
       "   93.67,\n",
       "   67.79,\n",
       "   56.07,\n",
       "   254.63,\n",
       "   96.63,\n",
       "   84.3,\n",
       "   246.34,\n",
       "   195.16,\n",
       "   93.34,\n",
       "   162.3,\n",
       "   106.4,\n",
       "   110.25,\n",
       "   69.7,\n",
       "   87.03,\n",
       "   112.98,\n",
       "   82.47,\n",
       "   75.88,\n",
       "   84.63,\n",
       "   109.56,\n",
       "   89.45,\n",
       "   121.14,\n",
       "   87.77,\n",
       "   106.56,\n",
       "   153.76,\n",
       "   88.65,\n",
       "   111.22,\n",
       "   223.68,\n",
       "   55.86,\n",
       "   63.73,\n",
       "   103.94,\n",
       "   92.49,\n",
       "   229.2,\n",
       "   75.06,\n",
       "   85.57,\n",
       "   68.61,\n",
       "   ...],\n",
       "  'bmi': [36.6,\n",
       "   32.5,\n",
       "   34.4,\n",
       "   24.0,\n",
       "   29.0,\n",
       "   27.4,\n",
       "   22.8,\n",
       "   24.2,\n",
       "   29.7,\n",
       "   36.8,\n",
       "   27.3,\n",
       "   28.2,\n",
       "   30.9,\n",
       "   37.5,\n",
       "   25.8,\n",
       "   37.8,\n",
       "   22.4,\n",
       "   48.9,\n",
       "   26.6,\n",
       "   27.2,\n",
       "   23.5,\n",
       "   28.3,\n",
       "   44.2,\n",
       "   25.4,\n",
       "   22.2,\n",
       "   30.5,\n",
       "   26.5,\n",
       "   33.7,\n",
       "   23.1,\n",
       "   32.0,\n",
       "   29.9,\n",
       "   23.9,\n",
       "   28.5,\n",
       "   26.4,\n",
       "   20.2,\n",
       "   33.6,\n",
       "   38.6,\n",
       "   39.2,\n",
       "   27.7,\n",
       "   31.4,\n",
       "   36.5,\n",
       "   33.2,\n",
       "   32.8,\n",
       "   40.4,\n",
       "   25.3,\n",
       "   30.2,\n",
       "   47.5,\n",
       "   20.3,\n",
       "   30.0,\n",
       "   28.9,\n",
       "   28.1,\n",
       "   31.1,\n",
       "   21.7,\n",
       "   27.0,\n",
       "   24.1,\n",
       "   45.9,\n",
       "   44.1,\n",
       "   22.9,\n",
       "   29.1,\n",
       "   32.3,\n",
       "   41.1,\n",
       "   25.6,\n",
       "   29.8,\n",
       "   26.3,\n",
       "   26.2,\n",
       "   29.4,\n",
       "   24.4,\n",
       "   28.0,\n",
       "   28.8,\n",
       "   34.6,\n",
       "   19.4,\n",
       "   30.3,\n",
       "   41.5,\n",
       "   22.6,\n",
       "   56.6,\n",
       "   27.1,\n",
       "   31.3,\n",
       "   31.0,\n",
       "   31.7,\n",
       "   35.8,\n",
       "   28.4,\n",
       "   20.1,\n",
       "   26.7,\n",
       "   38.7,\n",
       "   34.9,\n",
       "   25.0,\n",
       "   23.8,\n",
       "   21.8,\n",
       "   27.5,\n",
       "   24.6,\n",
       "   32.9,\n",
       "   26.1,\n",
       "   31.9,\n",
       "   34.1,\n",
       "   36.9,\n",
       "   37.3,\n",
       "   45.7,\n",
       "   34.2,\n",
       "   23.6,\n",
       "   22.3,\n",
       "   37.1,\n",
       "   45.0,\n",
       "   25.5,\n",
       "   30.8,\n",
       "   37.4,\n",
       "   34.5,\n",
       "   27.9,\n",
       "   29.5,\n",
       "   46.0,\n",
       "   42.5,\n",
       "   35.5,\n",
       "   26.9,\n",
       "   45.5,\n",
       "   31.5,\n",
       "   33.0,\n",
       "   23.4,\n",
       "   30.7,\n",
       "   20.5,\n",
       "   21.5,\n",
       "   40.0,\n",
       "   28.6,\n",
       "   42.2,\n",
       "   29.6,\n",
       "   35.4,\n",
       "   16.9,\n",
       "   26.8,\n",
       "   39.3,\n",
       "   32.6,\n",
       "   35.9,\n",
       "   21.2,\n",
       "   42.4,\n",
       "   40.5,\n",
       "   36.7,\n",
       "   29.3,\n",
       "   19.6,\n",
       "   18.0,\n",
       "   17.6,\n",
       "   19.1,\n",
       "   50.1,\n",
       "   17.7,\n",
       "   54.6,\n",
       "   35.0,\n",
       "   22.0,\n",
       "   39.4,\n",
       "   19.7,\n",
       "   22.5,\n",
       "   25.2,\n",
       "   41.8,\n",
       "   60.9,\n",
       "   23.7,\n",
       "   24.5,\n",
       "   31.2,\n",
       "   16.0,\n",
       "   31.6,\n",
       "   25.1,\n",
       "   24.8,\n",
       "   18.3,\n",
       "   20.0,\n",
       "   19.5,\n",
       "   36.0,\n",
       "   35.3,\n",
       "   40.1,\n",
       "   43.1,\n",
       "   21.4,\n",
       "   34.3,\n",
       "   27.6,\n",
       "   16.5,\n",
       "   24.3,\n",
       "   25.7,\n",
       "   21.9,\n",
       "   38.4,\n",
       "   25.9,\n",
       "   54.7,\n",
       "   18.6,\n",
       "   24.9,\n",
       "   48.2,\n",
       "   20.7,\n",
       "   39.5,\n",
       "   23.3,\n",
       "   64.8,\n",
       "   35.1,\n",
       "   43.6,\n",
       "   21.0,\n",
       "   47.3,\n",
       "   16.6,\n",
       "   21.6,\n",
       "   15.5,\n",
       "   35.6,\n",
       "   16.7,\n",
       "   41.9,\n",
       "   16.4,\n",
       "   17.1,\n",
       "   29.2,\n",
       "   37.9,\n",
       "   44.6,\n",
       "   39.6,\n",
       "   40.3,\n",
       "   41.6,\n",
       "   39.0,\n",
       "   23.2,\n",
       "   18.9,\n",
       "   36.1,\n",
       "   36.3,\n",
       "   46.5,\n",
       "   16.8,\n",
       "   46.6,\n",
       "   35.2,\n",
       "   20.9,\n",
       "   13.8,\n",
       "   31.8,\n",
       "   15.3,\n",
       "   38.2,\n",
       "   45.2,\n",
       "   17.0,\n",
       "   49.8,\n",
       "   27.8,\n",
       "   60.2,\n",
       "   23.0,\n",
       "   22.1,\n",
       "   26.0,\n",
       "   44.3,\n",
       "   51.0,\n",
       "   39.7,\n",
       "   34.7,\n",
       "   21.3,\n",
       "   41.2,\n",
       "   34.8,\n",
       "   19.2,\n",
       "   35.7,\n",
       "   40.8,\n",
       "   24.7,\n",
       "   19.0,\n",
       "   32.4,\n",
       "   34.0,\n",
       "   28.7,\n",
       "   32.1,\n",
       "   51.5,\n",
       "   20.4,\n",
       "   30.6,\n",
       "   71.9,\n",
       "   19.3,\n",
       "   40.9,\n",
       "   17.2,\n",
       "   16.1,\n",
       "   16.2,\n",
       "   40.6,\n",
       "   18.4,\n",
       "   21.1,\n",
       "   42.3,\n",
       "   32.2,\n",
       "   50.2,\n",
       "   17.5,\n",
       "   18.7,\n",
       "   42.1,\n",
       "   47.8,\n",
       "   20.8,\n",
       "   30.1,\n",
       "   17.3,\n",
       "   36.4,\n",
       "   12.0,\n",
       "   36.2,\n",
       "   55.7,\n",
       "   14.4,\n",
       "   43.0,\n",
       "   41.7,\n",
       "   33.8,\n",
       "   43.9,\n",
       "   22.7,\n",
       "   57.5,\n",
       "   37.0,\n",
       "   38.5,\n",
       "   16.3,\n",
       "   44.0,\n",
       "   32.7,\n",
       "   54.2,\n",
       "   40.2,\n",
       "   33.3,\n",
       "   17.4,\n",
       "   41.3,\n",
       "   52.3,\n",
       "   14.6,\n",
       "   17.8,\n",
       "   46.1,\n",
       "   33.1,\n",
       "   18.1,\n",
       "   43.8,\n",
       "   50.3,\n",
       "   38.9,\n",
       "   43.7,\n",
       "   39.9,\n",
       "   15.9,\n",
       "   19.8,\n",
       "   12.3,\n",
       "   78.0,\n",
       "   38.3,\n",
       "   41.0,\n",
       "   42.6,\n",
       "   43.4,\n",
       "   15.1,\n",
       "   20.6,\n",
       "   33.5,\n",
       "   43.2,\n",
       "   30.4,\n",
       "   38.0,\n",
       "   33.4,\n",
       "   44.9,\n",
       "   44.7,\n",
       "   37.6,\n",
       "   39.8,\n",
       "   53.4,\n",
       "   55.2,\n",
       "   42.0,\n",
       "   37.2,\n",
       "   42.8,\n",
       "   18.8,\n",
       "   42.9,\n",
       "   14.3,\n",
       "   37.7,\n",
       "   48.4,\n",
       "   50.6,\n",
       "   46.2,\n",
       "   49.5,\n",
       "   43.3,\n",
       "   33.9,\n",
       "   18.5,\n",
       "   44.5,\n",
       "   45.4,\n",
       "   55.0,\n",
       "   54.8,\n",
       "   19.9,\n",
       "   17.9,\n",
       "   15.6,\n",
       "   52.8,\n",
       "   15.2,\n",
       "   66.8,\n",
       "   55.1,\n",
       "   18.2,\n",
       "   48.5,\n",
       "   55.9,\n",
       "   57.3,\n",
       "   10.3,\n",
       "   14.1,\n",
       "   15.7,\n",
       "   56.0,\n",
       "   44.8,\n",
       "   13.4,\n",
       "   51.8,\n",
       "   38.1,\n",
       "   57.7,\n",
       "   44.4,\n",
       "   38.8,\n",
       "   49.3,\n",
       "   39.1,\n",
       "   54.0,\n",
       "   56.1,\n",
       "   97.6,\n",
       "   53.9,\n",
       "   13.7,\n",
       "   11.5,\n",
       "   41.4,\n",
       "   14.2,\n",
       "   49.4,\n",
       "   15.4,\n",
       "   45.1,\n",
       "   49.2,\n",
       "   48.7,\n",
       "   53.8,\n",
       "   42.7,\n",
       "   48.8,\n",
       "   52.7,\n",
       "   53.5,\n",
       "   50.5,\n",
       "   15.8,\n",
       "   45.3,\n",
       "   14.8,\n",
       "   51.9,\n",
       "   63.3,\n",
       "   40.7,\n",
       "   61.2,\n",
       "   48.0,\n",
       "   46.8,\n",
       "   48.3,\n",
       "   58.1,\n",
       "   50.4,\n",
       "   11.3,\n",
       "   12.8,\n",
       "   13.5,\n",
       "   14.5,\n",
       "   15.0,\n",
       "   59.7,\n",
       "   47.4,\n",
       "   52.5,\n",
       "   13.2,\n",
       "   52.9,\n",
       "   61.6,\n",
       "   49.9,\n",
       "   54.3,\n",
       "   47.9,\n",
       "   13.0,\n",
       "   13.9,\n",
       "   50.9,\n",
       "   57.2,\n",
       "   64.4,\n",
       "   92.0,\n",
       "   50.8,\n",
       "   57.9,\n",
       "   45.8,\n",
       "   47.6,\n",
       "   14.0,\n",
       "   46.4,\n",
       "   46.9,\n",
       "   47.1,\n",
       "   13.3,\n",
       "   48.1,\n",
       "   51.7,\n",
       "   46.3,\n",
       "   54.1,\n",
       "   14.9],\n",
       "  'smoking_status': ['formerly smoked', 'never smoked', 'smokes', 'Unknown'],\n",
       "  'stroke': [1, 0]},\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values_in_columns(stroke_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22aa573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the type of data the columns are\n",
    "\n",
    "stroke_df['avg_glucose_level'] = stroke_df['avg_glucose_level'].astype(int)\n",
    "stroke_df['bmi'] = stroke_df['bmi'].astype(int)\n",
    "stroke_df['age'] = stroke_df['age'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3395bf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Govt_job</th>\n",
       "      <th>Never_worked</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-employed</th>\n",
       "      <th>children</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Urban</th>\n",
       "      <th>...</th>\n",
       "      <th>formerly smoked</th>\n",
       "      <th>never smoked</th>\n",
       "      <th>smokes</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Other</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>age</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>228</td>\n",
       "      <td>36</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>105</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>171</td>\n",
       "      <td>34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>174</td>\n",
       "      <td>24</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>186</td>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>125</td>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>82</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>166</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>85</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4909 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hypertension  heart_disease ever_married  Govt_job  Never_worked  \\\n",
       "0                0              1          Yes     False         False   \n",
       "2                0              1          Yes     False         False   \n",
       "3                0              0          Yes     False         False   \n",
       "4                1              0          Yes     False         False   \n",
       "5                0              0          Yes     False         False   \n",
       "...            ...            ...          ...       ...           ...   \n",
       "5104             0              0           No     False         False   \n",
       "5106             0              0          Yes     False         False   \n",
       "5107             0              0          Yes     False         False   \n",
       "5108             0              0          Yes     False         False   \n",
       "5109             0              0          Yes      True         False   \n",
       "\n",
       "      Private  Self-employed  children  Rural  Urban  ...  formerly smoked  \\\n",
       "0        True          False     False  False   True  ...             True   \n",
       "2        True          False     False   True  False  ...            False   \n",
       "3        True          False     False  False   True  ...            False   \n",
       "4       False           True     False   True  False  ...            False   \n",
       "5        True          False     False  False   True  ...             True   \n",
       "...       ...            ...       ...    ...    ...  ...              ...   \n",
       "5104    False          False      True   True  False  ...            False   \n",
       "5106    False           True     False  False   True  ...            False   \n",
       "5107    False           True     False   True  False  ...            False   \n",
       "5108     True          False     False   True  False  ...             True   \n",
       "5109    False          False     False  False   True  ...            False   \n",
       "\n",
       "      never smoked  smokes  Female   Male  Other  avg_glucose_level  bmi  age  \\\n",
       "0            False   False   False   True  False                228   36   67   \n",
       "2             True   False   False   True  False                105   32   80   \n",
       "3            False    True    True  False  False                171   34   49   \n",
       "4             True   False    True  False  False                174   24   79   \n",
       "5            False   False   False   True  False                186   29   81   \n",
       "...            ...     ...     ...    ...    ...                ...  ...  ...   \n",
       "5104         False   False    True  False  False                103   18   13   \n",
       "5106          True   False    True  False  False                125   40   81   \n",
       "5107          True   False    True  False  False                 82   30   35   \n",
       "5108         False   False   False   True  False                166   25   51   \n",
       "5109         False   False    True  False  False                 85   26   44   \n",
       "\n",
       "      stroke  \n",
       "0          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "...      ...  \n",
       "5104       0  \n",
       "5106       0  \n",
       "5107       0  \n",
       "5108       0  \n",
       "5109       0  \n",
       "\n",
       "[4909 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding the data so that it can be used to train the model\n",
    "# doing so for data that has atleast 2 qualitative inputs\n",
    "\n",
    "work_encoded = pd.get_dummies(stroke_df['work_type'])\n",
    "gender_encoded = pd.get_dummies(stroke_df['gender'])\n",
    "residence_encoded = pd.get_dummies(stroke_df['Residence_type'])\n",
    "smoking_encoded = pd.get_dummies(stroke_df['smoking_status'])\n",
    "\n",
    "stroke_df = pd.concat([stroke_df['hypertension'], stroke_df['heart_disease'],\n",
    "                       stroke_df['ever_married'], work_encoded, \n",
    "                       residence_encoded, smoking_encoded, gender_encoded,\n",
    "                       stroke_df['avg_glucose_level'], stroke_df['bmi'],\n",
    "                       stroke_df['age'], stroke_df['stroke']], axis =1 )\n",
    "\n",
    "stroke_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1c5949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4909 entries, 0 to 5109\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   hypertension       4909 non-null   int64 \n",
      " 1   heart_disease      4909 non-null   int64 \n",
      " 2   ever_married       4909 non-null   object\n",
      " 3   Govt_job           4909 non-null   bool  \n",
      " 4   Never_worked       4909 non-null   bool  \n",
      " 5   Private            4909 non-null   bool  \n",
      " 6   Self-employed      4909 non-null   bool  \n",
      " 7   children           4909 non-null   bool  \n",
      " 8   Rural              4909 non-null   bool  \n",
      " 9   Urban              4909 non-null   bool  \n",
      " 10  Unknown            4909 non-null   bool  \n",
      " 11  formerly smoked    4909 non-null   bool  \n",
      " 12  never smoked       4909 non-null   bool  \n",
      " 13  smokes             4909 non-null   bool  \n",
      " 14  Female             4909 non-null   bool  \n",
      " 15  Male               4909 non-null   bool  \n",
      " 16  Other              4909 non-null   bool  \n",
      " 17  avg_glucose_level  4909 non-null   int64 \n",
      " 18  bmi                4909 non-null   int64 \n",
      " 19  age                4909 non-null   int64 \n",
      " 20  stroke             4909 non-null   int64 \n",
      "dtypes: bool(14), int64(6), object(1)\n",
      "memory usage: 373.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'hypertension': [0, 1],\n",
       "  'heart_disease': [1, 0],\n",
       "  'ever_married': ['Yes', 'No'],\n",
       "  'Govt_job': [False, True],\n",
       "  'Never_worked': [False, True],\n",
       "  'Private': [True, False],\n",
       "  'Self-employed': [False, True],\n",
       "  'children': [False, True],\n",
       "  'Rural': [False, True],\n",
       "  'Urban': [True, False],\n",
       "  'Unknown': [False, True],\n",
       "  'formerly smoked': [True, False],\n",
       "  'never smoked': [False, True],\n",
       "  'smokes': [False, True],\n",
       "  'Female': [False, True],\n",
       "  'Male': [True, False],\n",
       "  'Other': [False, True],\n",
       "  'avg_glucose_level': [228,\n",
       "   105,\n",
       "   171,\n",
       "   174,\n",
       "   186,\n",
       "   70,\n",
       "   94,\n",
       "   58,\n",
       "   80,\n",
       "   120,\n",
       "   104,\n",
       "   214,\n",
       "   167,\n",
       "   191,\n",
       "   221,\n",
       "   89,\n",
       "   193,\n",
       "   233,\n",
       "   208,\n",
       "   102,\n",
       "   100,\n",
       "   195,\n",
       "   212,\n",
       "   83,\n",
       "   196,\n",
       "   252,\n",
       "   84,\n",
       "   219,\n",
       "   74,\n",
       "   92,\n",
       "   60,\n",
       "   78,\n",
       "   71,\n",
       "   144,\n",
       "   213,\n",
       "   243,\n",
       "   107,\n",
       "   99,\n",
       "   127,\n",
       "   124,\n",
       "   59,\n",
       "   194,\n",
       "   180,\n",
       "   185,\n",
       "   61,\n",
       "   93,\n",
       "   113,\n",
       "   86,\n",
       "   72,\n",
       "   179,\n",
       "   116,\n",
       "   96,\n",
       "   66,\n",
       "   240,\n",
       "   110,\n",
       "   143,\n",
       "   88,\n",
       "   79,\n",
       "   111,\n",
       "   98,\n",
       "   226,\n",
       "   68,\n",
       "   64,\n",
       "   235,\n",
       "   76,\n",
       "   82,\n",
       "   190,\n",
       "   231,\n",
       "   73,\n",
       "   129,\n",
       "   224,\n",
       "   216,\n",
       "   62,\n",
       "   259,\n",
       "   249,\n",
       "   131,\n",
       "   200,\n",
       "   130,\n",
       "   182,\n",
       "   206,\n",
       "   263,\n",
       "   140,\n",
       "   207,\n",
       "   199,\n",
       "   103,\n",
       "   151,\n",
       "   67,\n",
       "   239,\n",
       "   223,\n",
       "   77,\n",
       "   203,\n",
       "   133,\n",
       "   162,\n",
       "   91,\n",
       "   97,\n",
       "   56,\n",
       "   112,\n",
       "   137,\n",
       "   215,\n",
       "   205,\n",
       "   118,\n",
       "   271,\n",
       "   242,\n",
       "   175,\n",
       "   90,\n",
       "   109,\n",
       "   87,\n",
       "   106,\n",
       "   134,\n",
       "   95,\n",
       "   210,\n",
       "   250,\n",
       "   184,\n",
       "   81,\n",
       "   218,\n",
       "   211,\n",
       "   197,\n",
       "   247,\n",
       "   57,\n",
       "   69,\n",
       "   161,\n",
       "   85,\n",
       "   75,\n",
       "   198,\n",
       "   55,\n",
       "   149,\n",
       "   117,\n",
       "   114,\n",
       "   141,\n",
       "   146,\n",
       "   220,\n",
       "   115,\n",
       "   234,\n",
       "   229,\n",
       "   138,\n",
       "   101,\n",
       "   136,\n",
       "   126,\n",
       "   63,\n",
       "   251,\n",
       "   123,\n",
       "   122,\n",
       "   178,\n",
       "   147,\n",
       "   139,\n",
       "   225,\n",
       "   227,\n",
       "   145,\n",
       "   201,\n",
       "   170,\n",
       "   217,\n",
       "   132,\n",
       "   65,\n",
       "   183,\n",
       "   108,\n",
       "   155,\n",
       "   189,\n",
       "   163,\n",
       "   188,\n",
       "   204,\n",
       "   125,\n",
       "   158,\n",
       "   148,\n",
       "   156,\n",
       "   121,\n",
       "   119,\n",
       "   222,\n",
       "   128,\n",
       "   173,\n",
       "   152,\n",
       "   254,\n",
       "   160,\n",
       "   135,\n",
       "   237,\n",
       "   236,\n",
       "   142,\n",
       "   232,\n",
       "   157,\n",
       "   165,\n",
       "   246,\n",
       "   153,\n",
       "   230,\n",
       "   267,\n",
       "   150,\n",
       "   181,\n",
       "   169,\n",
       "   244,\n",
       "   154,\n",
       "   253,\n",
       "   238,\n",
       "   168,\n",
       "   202,\n",
       "   176,\n",
       "   187,\n",
       "   209,\n",
       "   164,\n",
       "   192,\n",
       "   266,\n",
       "   172,\n",
       "   255,\n",
       "   159,\n",
       "   248,\n",
       "   261,\n",
       "   256,\n",
       "   166,\n",
       "   177],\n",
       "  'bmi': [36,\n",
       "   32,\n",
       "   34,\n",
       "   24,\n",
       "   29,\n",
       "   27,\n",
       "   22,\n",
       "   28,\n",
       "   30,\n",
       "   37,\n",
       "   25,\n",
       "   48,\n",
       "   26,\n",
       "   23,\n",
       "   44,\n",
       "   33,\n",
       "   20,\n",
       "   38,\n",
       "   39,\n",
       "   31,\n",
       "   40,\n",
       "   47,\n",
       "   21,\n",
       "   45,\n",
       "   41,\n",
       "   19,\n",
       "   56,\n",
       "   35,\n",
       "   46,\n",
       "   42,\n",
       "   16,\n",
       "   18,\n",
       "   17,\n",
       "   50,\n",
       "   54,\n",
       "   60,\n",
       "   43,\n",
       "   64,\n",
       "   15,\n",
       "   13,\n",
       "   49,\n",
       "   51,\n",
       "   71,\n",
       "   12,\n",
       "   55,\n",
       "   14,\n",
       "   57,\n",
       "   52,\n",
       "   78,\n",
       "   53,\n",
       "   66,\n",
       "   10,\n",
       "   97,\n",
       "   11,\n",
       "   63,\n",
       "   61,\n",
       "   58,\n",
       "   59,\n",
       "   92],\n",
       "  'age': [67,\n",
       "   80,\n",
       "   49,\n",
       "   79,\n",
       "   81,\n",
       "   74,\n",
       "   69,\n",
       "   78,\n",
       "   61,\n",
       "   54,\n",
       "   50,\n",
       "   64,\n",
       "   75,\n",
       "   60,\n",
       "   71,\n",
       "   52,\n",
       "   82,\n",
       "   65,\n",
       "   57,\n",
       "   42,\n",
       "   48,\n",
       "   72,\n",
       "   58,\n",
       "   76,\n",
       "   39,\n",
       "   77,\n",
       "   63,\n",
       "   73,\n",
       "   56,\n",
       "   45,\n",
       "   70,\n",
       "   59,\n",
       "   66,\n",
       "   43,\n",
       "   68,\n",
       "   47,\n",
       "   53,\n",
       "   38,\n",
       "   55,\n",
       "   46,\n",
       "   32,\n",
       "   51,\n",
       "   14,\n",
       "   3,\n",
       "   8,\n",
       "   37,\n",
       "   40,\n",
       "   35,\n",
       "   20,\n",
       "   44,\n",
       "   25,\n",
       "   27,\n",
       "   23,\n",
       "   17,\n",
       "   13,\n",
       "   4,\n",
       "   16,\n",
       "   22,\n",
       "   30,\n",
       "   29,\n",
       "   11,\n",
       "   21,\n",
       "   18,\n",
       "   33,\n",
       "   24,\n",
       "   36,\n",
       "   0,\n",
       "   34,\n",
       "   41,\n",
       "   5,\n",
       "   26,\n",
       "   31,\n",
       "   7,\n",
       "   12,\n",
       "   62,\n",
       "   2,\n",
       "   9,\n",
       "   15,\n",
       "   28,\n",
       "   10,\n",
       "   1,\n",
       "   19,\n",
       "   6],\n",
       "  'stroke': [1, 0]},\n",
       " None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the datatype of the dataset\n",
    "\n",
    "unique_values_in_columns(stroke_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ebb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the bool input into an integer\n",
    "\n",
    "def convert(dataframe):\n",
    "    for column in dataframe.columns:\n",
    "        if dataframe[column].dtype == bool:\n",
    "            dataframe[column] = dataframe[column].astype(int)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9749d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ever_married\n",
      "Yes    3204\n",
      "No     1705\n",
      "Name: count, dtype: int64\n",
      "ever_married\n",
      "1    3204\n",
      "0    1705\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Converting the data inputs of \"yes\" or \"no\" into 0 or 1, respectively\n",
    "\n",
    "print (stroke_df['ever_married'].value_counts())\n",
    "stroke_df['ever_married'].replace(['No', 'Yes'], [0,1], inplace = True)\n",
    "print (stroke_df['ever_married'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e5d16aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Govt_job</th>\n",
       "      <th>Never_worked</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-employed</th>\n",
       "      <th>children</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Urban</th>\n",
       "      <th>...</th>\n",
       "      <th>formerly smoked</th>\n",
       "      <th>never smoked</th>\n",
       "      <th>smokes</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Other</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>age</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>36</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>24</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4909 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hypertension  heart_disease  ever_married  Govt_job  Never_worked  \\\n",
       "0                0              1             1         0             0   \n",
       "2                0              1             1         0             0   \n",
       "3                0              0             1         0             0   \n",
       "4                1              0             1         0             0   \n",
       "5                0              0             1         0             0   \n",
       "...            ...            ...           ...       ...           ...   \n",
       "5104             0              0             0         0             0   \n",
       "5106             0              0             1         0             0   \n",
       "5107             0              0             1         0             0   \n",
       "5108             0              0             1         0             0   \n",
       "5109             0              0             1         1             0   \n",
       "\n",
       "      Private  Self-employed  children  Rural  Urban  ...  formerly smoked  \\\n",
       "0           1              0         0      0      1  ...                1   \n",
       "2           1              0         0      1      0  ...                0   \n",
       "3           1              0         0      0      1  ...                0   \n",
       "4           0              1         0      1      0  ...                0   \n",
       "5           1              0         0      0      1  ...                1   \n",
       "...       ...            ...       ...    ...    ...  ...              ...   \n",
       "5104        0              0         1      1      0  ...                0   \n",
       "5106        0              1         0      0      1  ...                0   \n",
       "5107        0              1         0      1      0  ...                0   \n",
       "5108        1              0         0      1      0  ...                1   \n",
       "5109        0              0         0      0      1  ...                0   \n",
       "\n",
       "      never smoked  smokes  Female  Male  Other  avg_glucose_level  bmi  age  \\\n",
       "0                0       0       0     1      0                228   36   67   \n",
       "2                1       0       0     1      0                105   32   80   \n",
       "3                0       1       1     0      0                171   34   49   \n",
       "4                1       0       1     0      0                174   24   79   \n",
       "5                0       0       0     1      0                186   29   81   \n",
       "...            ...     ...     ...   ...    ...                ...  ...  ...   \n",
       "5104             0       0       1     0      0                103   18   13   \n",
       "5106             1       0       1     0      0                125   40   81   \n",
       "5107             1       0       1     0      0                 82   30   35   \n",
       "5108             0       0       0     1      0                166   25   51   \n",
       "5109             0       0       1     0      0                 85   26   44   \n",
       "\n",
       "      stroke  \n",
       "0          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "...      ...  \n",
       "5104       0  \n",
       "5106       0  \n",
       "5107       0  \n",
       "5108       0  \n",
       "5109       0  \n",
       "\n",
       "[4909 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the conversion function made ealier to convert that data into 0 or 1\n",
    "\n",
    "convert(stroke_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34ba3349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   1   0   0   1   0   0   0   1   0   1   0   0   0   1   0 228\n",
      "   36  67   1]\n",
      " [  0   1   1   0   0   1   0   0   1   0   0   0   1   0   0   1   0 105\n",
      "   32  80   1]\n",
      " [  0   0   1   0   0   1   0   0   0   1   0   0   0   1   1   0   0 171\n",
      "   34  49   1]\n",
      " [  1   0   1   0   0   0   1   0   1   0   0   0   1   0   1   0   0 174\n",
      "   24  79   1]\n",
      " [  0   0   1   0   0   1   0   0   0   1   0   1   0   0   0   1   0 186\n",
      "   29  81   1]]\n"
     ]
    }
   ],
   "source": [
    "#Convert Data to a numpy Array\n",
    "\n",
    "stroke_np = stroke_df.values\n",
    "\n",
    "\n",
    "#Preview of the first 5 rows\n",
    "\n",
    "print(stroke_np[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85014cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the features - set a X  and our target - set as Y\n",
    "X = stroke_np[:,:20]\n",
    "Y = stroke_np[:,20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fd9830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4909, 20)\n",
      "(4909, 1)\n",
      "[[  0   0   1   1   0   0   0   0   1   0   0   0   1   0   1   0   0 104\n",
      "   26  31   0]\n",
      " [  0   1   1   0   0   0   1   0   0   1   0   0   1   0   0   1   0 187\n",
      "   34  51   0]\n",
      " [  0   0   0   0   0   1   0   0   0   1   0   0   1   0   1   0   0  74\n",
      "   28  59   0]\n",
      " [  0   0   1   0   0   1   0   0   1   0   1   0   0   0   1   0   0  68\n",
      "   33  75   0]\n",
      " [  0   0   1   0   0   1   0   0   1   0   0   0   0   1   1   0   0  83\n",
      "   42  37   0]]\n"
     ]
    }
   ],
   "source": [
    "# Stack them together for shuffling and shuffled the data points to counter pattern recognition of the sequence\n",
    "\n",
    "X_and_Y = np.hstack((X, Y))            \n",
    "np.random.shuffle(X_and_Y)     \n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_and_Y[:5])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6749ea21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0,   0,   1, ..., 104,  26,  31],\n",
       "        [  0,   1,   1, ..., 187,  34,  51],\n",
       "        [  0,   0,   0, ...,  74,  28,  59],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,  56,  21,  19],\n",
       "        [  0,   0,   0, ...,  71,  19,  81],\n",
       "        [  0,   1,   1, ...,  91,  23,  56]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting X and Y as shuffled\n",
    "\n",
    "\n",
    "X_shuffled = X_and_Y[:,:20]\n",
    "Y_shuffled = X_and_Y[:,20:]\n",
    "\n",
    "X_shuffled, Y_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f6216",
   "metadata": {},
   "source": [
    "# Functions for Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad7e5c",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "753a1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for DT to be applied to all datasets\n",
    "\n",
    "def DT(X_Test, X_Train, Y_Test, Y_Train):\n",
    "    \n",
    "    D_list = np.array([1, 2, 3, 4, 5]) # list of parameters\n",
    "    parameters = {'max_depth': D_list}  \n",
    "    \n",
    "    #Creating the model that will be used to train the data and fitting the data\n",
    "    DT.DT_model = DecisionTreeClassifier()\n",
    "    DT.DT_model = GridSearchCV(DT.DT_model, parameters, return_train_score=True) #finding the best parameter depth\n",
    "    DT.DT_model.fit(X_Train, Y_Train)\n",
    "\n",
    "    Y_pred = DT.DT_model.predict(X_Test).astype('int') #Creating predictions from the fitted data\n",
    "    \n",
    "    #Getting accuracy socre and precision\n",
    "    # Creating a heat map of what was being classified as what (0 no, 1 yes)\n",
    "    DT.accuracy = accuracy_score(Y_Test, Y_pred)\n",
    "    conf_matrix = confusion_matrix(Y_Test, Y_pred)\n",
    "    classification_rep = classification_report(Y_Test, Y_pred)\n",
    "    DT.precision = precision_score(Y_Test, Y_pred)\n",
    "    print(\"Accuracy:\", DT.accuracy)\n",
    "    print(\"Precision:\", DT.precision)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_rep)\n",
    "    \n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "\n",
    "# Customize the plot\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "# Show the plot\n",
    "    plt.show()\n",
    "    print(\"Accuracy:\", DT.accuracy)\n",
    "    print(\"Precision:\", DT.precision)\n",
    "    \n",
    "    DT.accuracy_Train = DT.DT_model.score(X_Train, Y_Train)\n",
    "    DT.optimal_classifier = DT.DT_model.best_params_['max_depth']\n",
    "\n",
    "    return DT.accuracy, DT.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75454c81",
   "metadata": {},
   "source": [
    "## SVM Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae029c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_Test, X_Train, Y_Test, Y_Train):\n",
    "    \n",
    "    C_list     = [10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 1] # Different parameters to try\n",
    "    parameters = {'C': C_list}\n",
    "    \n",
    "    #fit the classifier with the training data\n",
    "    SVM.SVM_model = svm.SVC()\n",
    "    SVM.SVM_model = GridSearchCV(SVM.SVM_model, parameters)#Perform a grid Search to identify the best C\n",
    "    SVM.SVM_model.fit(X_Train, Y_Train)\n",
    "    Y_pred = SVM.SVM_model.predict(X_Test) #creating predictions fitted data\n",
    "    \n",
    "    #Getting accuracy socre and precision\n",
    "    # Creating a heat map of what was being classified as what (0 no, 1 yes)\n",
    "    SVM.accuracy = accuracy_score(Y_Test, Y_pred)\n",
    "    conf_matrix = confusion_matrix(Y_Test, Y_pred)\n",
    "    classification_rep = classification_report(Y_Test, Y_pred)\n",
    "        \n",
    "    SVM.precision = precision_score(Y_Test, Y_pred)\n",
    "        \n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_rep)\n",
    "    \n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "\n",
    "# Customize the plot\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "# Show the plot\n",
    "    plt.show()\n",
    "    print(\"Accuracy:\", SVM.accuracy)\n",
    "    print(\"Precision:\", SVM.precision)\n",
    "        \n",
    "    SVM.accuracy_Train = SVM.SVM_model.score(X_Train, Y_Train)\n",
    "     #Find the optimal C parameter and use that to redefine the classifier\n",
    "    SVM.optimal_classifier = svm.SVC(kernel = 'linear', C = SVM.SVM_model.best_params_['C'] )\n",
    "\n",
    "    \n",
    "    return SVM.accuracy, SVM.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856d709",
   "metadata": {},
   "source": [
    "## Log Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6e965bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOG(X_Test, X_Train, Y_Test, Y_Train):\n",
    "    L_list = np.array([0.00001, 0.0001, 0.001, 0.01, 0.1, 1]) # List of potential C parameters\n",
    "    parameters = {'C':L_list}\n",
    "    \n",
    "    #Creating the model and Fitting the data\n",
    "    LOG.LOG_model = LogisticRegression()\n",
    "    LOG.LOG_model = GridSearchCV(LOG.LOG_model, parameters) #Perform a grid Search to identify the best C\n",
    "    LOG.LOG_model.fit(X_Train, Y_Train)\n",
    "    Y_pred = LOG.LOG_model.predict(X_Test) #Finding the predictions from the fitted data\n",
    "    \n",
    "    #Getting accuracy socre and precision\n",
    "    # Creating a heat map of what was being classified as what (0 no, 1 yes)\n",
    "    LOG.accuracy = accuracy_score(Y_Test, Y_pred)\n",
    "    conf_matrix = confusion_matrix(Y_Test, Y_pred)\n",
    "    classification_rep = classification_report(Y_Test, Y_pred)\n",
    "    LOG.precision = precision_score(Y_Test, Y_pred)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_rep)\n",
    "    \n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "\n",
    "# Customize the plot\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "# Show the plot\n",
    "    plt.show()\n",
    "    print(\"Accuracy:\", LOG.accuracy)\n",
    "    print(\"Precision:\", LOG.precision)\n",
    "    \n",
    "    LOG.accuracy_Train = LOG.LOG_model.score(X_Train, Y_Train)\n",
    "    LOG.optimal_classifier = LOG.LOG_model.best_params_['C']\n",
    "\n",
    "    return LOG.accuracy, LOG.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8557d",
   "metadata": {},
   "source": [
    "## KNN Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a77c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn (Test_X, Train_X, Test_Y, Train_Y):\n",
    "    \n",
    "    k_list = np.array([1, 2, 3, 4, 5, 6]) # List of potential n neighbor parameters\n",
    "    parameters = {'n_neighbors':k_list}\n",
    "    \n",
    "    #Getting accuracy socre and precision\n",
    "    # Creating a heat map of what was being classified as what (0 no, 1 yes)\n",
    "    knn.knn_model = KNeighborsClassifier()\n",
    "    knn.knn_model = GridSearchCV(knn.knn_model, parameters)\n",
    "    knn.knn_model.fit(Train_X, Train_Y)\n",
    "    Y_pred = knn.knn_model.predict(Test_X)\n",
    "    \n",
    "    #Getting accuracy socre and precision\n",
    "    # Creating a heat map of what was being classified as what (0 no, 1 yes)\n",
    "    knn.accuracy = accuracy_score(Test_Y, Y_pred)\n",
    "    conf_matrix = confusion_matrix(Test_Y, Y_pred)\n",
    "    classification_rep = classification_report(Test_Y,Y_pred)\n",
    "    knn.precision = precision_score(Test_Y, Y_pred)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_rep)\n",
    "    \n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "# Customize the plot\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "# Show the plot\n",
    "    plt.show()\n",
    "    print(\"Accuracy:\", knn.accuracy)\n",
    "    print(\"Precision:\", knn.precision)\n",
    "\n",
    "    knn.accuracy_Train = knn.knn_model.score(Train_X, Train_Y)\n",
    "    knn.optimal_classifier = knn.knn_model.best_params_['n_neighbors']\n",
    "\n",
    "    return knn.accuracy, knn.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bcabe5",
   "metadata": {},
   "source": [
    "## Muliti Layer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9832ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(Test_X, Train_X, Test_Y, Train_Y):\n",
    "    \n",
    "    # Creating a model with specific solver, alpha, and hidden layer size\n",
    "    MLP.MLP_model =  MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                           hidden_layer_sizes=(5,5), random_state=1)\n",
    "    MLP.MLP_model.fit(Train_X,Train_Y)\n",
    "    Y_pred = MLP.MLP_model.predict(Test_X)\n",
    "    \n",
    "    #Getting accuracy socre and precision\n",
    "    # Creating a heat map of what was being classified as what (0 no, 1 yes)\n",
    "    MLP.accuracy = accuracy_score(Test_Y, Y_pred)\n",
    "    conf_matrix = confusion_matrix(Test_Y, Y_pred)\n",
    "    classification_rep = classification_report(Test_Y,Y_pred)\n",
    "    MLP.precision = precision_score(Test_Y, Y_pred)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_rep)\n",
    "    \n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "# Customize the plot\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "# Show the plot\n",
    "    plt.show()\n",
    "    print(\"Accuracy:\", MLP.accuracy)\n",
    "    print(\"Precision:\", MLP.precision)\n",
    "    MLP.accuracy_Train = MLP.MLP_model.score(Train_X, Train_Y)\n",
    "\n",
    "    return MLP.accuracy, MLP.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e18f18",
   "metadata": {},
   "source": [
    "# Running the Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083950a",
   "metadata": {},
   "source": [
    "## Decision Tree Classifer - Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e960fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data into 20/80, 50/50, and 80/20\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X_shuffled, Y_shuffled, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X_shuffled, Y_shuffled, test_size=0.5, random_state=42)\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X_shuffled, Y_shuffled, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da19dbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9592668024439919\n",
      "Precision: 0.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[942   0]\n",
      " [ 40   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       942\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.96       982\n",
      "   macro avg       0.48      0.50      0.49       982\n",
      "weighted avg       0.92      0.96      0.94       982\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9592668024439919\n",
      "Precision: 0.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1115/1003978571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy_DT1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprecision_DT1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_DT1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy_tr_DT1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1115/937135459.py\u001b[0m in \u001b[0;36mDT\u001b[0;34m(X_Test, X_Train, Y_Test, Y_Train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_Train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimal_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "DT(X_test1, X_train1, Y_test1, Y_train1)\n",
    "accuracy_DT1 = DT.accuracy\n",
    "precision_DT1 = DT.precision\n",
    "model_DT1 = DT.DT_model\n",
    "accuracy_tr_DT1 = DT.accuracy_Train\n",
    "opt_classifier1 = DT.optimal_classifier\n",
    "print(opt_classifier1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "702e8bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9230142566191446\n",
      "Precision: 0.08490566037735849\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2257   97]\n",
      " [  92    9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      2354\n",
      "           1       0.08      0.09      0.09       101\n",
      "\n",
      "    accuracy                           0.92      2455\n",
      "   macro avg       0.52      0.52      0.52      2455\n",
      "weighted avg       0.92      0.92      0.92      2455\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9230142566191446\n",
      "Precision: 0.08490566037735849\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "DT(X_test2, X_train2, Y_test2, Y_train2)\n",
    "accuracy_DT2 = DT.accuracy\n",
    "precision_DT2 = DT.precision\n",
    "model_DT2 = DT.DT_model\n",
    "accuracy_tr_DT2 = DT.accuracy_Train\n",
    "opt_classifier2 = DT.optimal_classifier\n",
    "print(opt_classifier2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85d3a1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9187881873727087\n",
      "Precision: 0.10837438423645321\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3587  181]\n",
      " [ 138   22]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      3768\n",
      "           1       0.11      0.14      0.12       160\n",
      "\n",
      "    accuracy                           0.92      3928\n",
      "   macro avg       0.54      0.54      0.54      3928\n",
      "weighted avg       0.93      0.92      0.92      3928\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9187881873727087\n",
      "Precision: 0.10837438423645321\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "DT(X_test3, X_train3, Y_test3, Y_train3)\n",
    "accuracy_DT3 = DT.accuracy\n",
    "precision_DT3 = DT.precision\n",
    "model_DT3= DT.DT_model\n",
    "accuracy_tr_DT3 = DT.accuracy_Train\n",
    "opt_classifier3 = DT.optimal_classifier\n",
    "print(opt_classifier3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17cf78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing a 5-fold cross validation\n",
    "score_DT1 = np.average( cross_val_score(model_DT1, X_train1, Y_train1, cv=5) )\n",
    "score_DT2 = np.average( cross_val_score(model_DT2, X_train2, Y_train2, cv=5) )\n",
    "score_DT3 = np.average( cross_val_score(model_DT3, X_train3, Y_train3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9ddf6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Test Accuracy 20/80 split: 0.9124236252545825\n",
      "DT Test Accuracy 50/50 split: 0.9230142566191446\n",
      "DT Test Accuracy 80/20 split: 0.9187881873727087\n",
      "\n",
      "DT Train Accuracy 20/80 split: 1.0\n",
      "DT Train Accuracy 50/50 split: 1.0\n",
      "DT Train Accuracy 80/20 split: 1.0\n",
      "\n",
      "DT Validation Accuracy 20/80 split: 0.9182583750668547\n",
      "DT Validation Accuracy 50/50 split: 0.9180980090610582\n",
      "DT Validation Accuracy 80/20 split: 0.8950119133947997\n",
      "\n",
      "DT Accuracy 20/80 split: 0.9435606667738125\n",
      "DT Accuracy 50/50 split: 0.947037421893401\n",
      "DT Accuracy 80/20 split: 0.9379333669225027\n",
      "\n",
      "Best Cs: 1 , 1 , 1\n"
     ]
    }
   ],
   "source": [
    "#results\n",
    "print('DT Test Accuracy 20/80 split:', accuracy_DT1)\n",
    "print('DT Test Accuracy 50/50 split:', accuracy_DT2)\n",
    "print('DT Test Accuracy 80/20 split:', accuracy_DT3)\n",
    "print('')\n",
    "print('DT Train Accuracy 20/80 split:', accuracy_tr_DT1)\n",
    "print('DT Train Accuracy 50/50 split:', accuracy_tr_DT2)\n",
    "print('DT Train Accuracy 80/20 split:', accuracy_tr_DT3)\n",
    "print('')\n",
    "print('DT Validation Accuracy 20/80 split:', score_DT1)\n",
    "print('DT Validation Accuracy 50/50 split:', score_DT2)\n",
    "print('DT Validation Accuracy 80/20 split:', score_DT3)\n",
    "print('')\n",
    "print('DT Accuracy 20/80 split:', (accuracy_DT1+accuracy_tr_DT1+score_DT1)/3)\n",
    "print('DT Accuracy 50/50 split:', (accuracy_DT2+accuracy_tr_DT2+score_DT2)/3)\n",
    "print('DT Accuracy 80/20 split:', (accuracy_DT3+accuracy_tr_DT3+score_DT3)/3)\n",
    "print('')\n",
    "print('Best Cs:', opt_classifier1, ',',opt_classifier2,',', opt_classifier3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b16f2",
   "metadata": {},
   "source": [
    "##  SVM Classifer - Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34be27a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[940   0]\n",
      " [ 42   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       940\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.96       982\n",
      "   macro avg       0.48      0.50      0.49       982\n",
      "weighted avg       0.92      0.96      0.94       982\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9572301425661914\n",
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "SVM(X_test1, X_train1, Y_test1, Y_train1)\n",
    "accuracy_SVM1 = SVM.accuracy\n",
    "precision_SVM1 = SVM.precision\n",
    "model_SVM1 = SVM.SVM_model\n",
    "accuracy_tr_SVM1 = SVM.accuracy_Train\n",
    "best_C1 = SVM.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1da9ec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[2354    0]\n",
      " [ 101    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2354\n",
      "           1       0.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.96      2455\n",
      "   macro avg       0.48      0.50      0.49      2455\n",
      "weighted avg       0.92      0.96      0.94      2455\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAV4klEQVR4nO3deZRdZZnv8e8jRUgYJSEpIiSATDYik8gkEkBtiQENjV5AtMUFhkHQq92KtjQISEQERRagMk8ySANeMBBwBZDJe0k6hhmBZoyEkBAIENAklef+cXbFSlFVqZR16lTq/X7WqrXO3u8+735O5eR33vPuoSIzkSQNfO9pdAGSpL5h4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLA14AREUMi4uaImB8R1/0D/RwSEbf3Zm2NEBG3RsSXG12H+g8DX30uIr4QEdMi4q2ImFUF0+690PXngGZgWGZ+vqedZOavM/Ofe6GeZUTEnhGREXFDu/XbVuvv6mY/P4iIK5e3XWaOzczLeliuBiADX30qIr4FnAVMpBbOo4HzgM/2QvcbAU9m5uJe6Kte5gC7RcSwNuu+DDzZWzuIGv9v6118U6jPRMQ6wMnA1zLzhsxckJmLMvPmzPx2tc1qEXFWRLxU/ZwVEatVbXtGxMyI+LeIeKX6dvCVqu0k4ATgwOqbw2HtR8IRsXE1km6qlg+NiGci4s2IeDYiDmmz/t42z9stIqZWU0VTI2K3Nm13RcQpEXFf1c/tEbFeF7+GhcBvgYOq568C/C/g1+1+Vz+PiBcj4o2I+O+I+Fi1fh/gP9q8zgfb1HFqRNwHvA28v1p3eNX+i4j4rzb9/zgipkREdPffTys/A199aVdgMHBjF9t8H9gF2A7YFtgJOL5N+/rAOsAGwGHAuRGxbmaeSO1bw7WZuWZmXtRVIRGxBnA2MDYz1wJ2A2Z0sN1QYFK17TDgp8CkdiP0LwBfAUYAg4B/72rfwOXAv1aPPwU8CrzUbpup1H4HQ4GrgOsiYnBmTm73Ordt85wvAROAtYDn2/X3b8A21YfZx6j97r6c3lulKAa++tIwYO5yplwOAU7OzFcycw5wErUga7Woal+UmbcAbwFb9rCeJcDWETEkM2dl5qMdbDMOeCozr8jMxZl5NfAEsF+bbS7JzCcz8x3gN9SCulOZeT8wNCK2pBb8l3ewzZWZ+Wq1zzOB1Vj+67w0Mx+tnrOoXX9vA1+k9oF1JXBsZs5cTn8aYAx89aVXgfVap1Q68T6WHZ0+X61b2ke7D4y3gTVXtJDMXAAcCBwJzIqISRHxgW7U01rTBm2WX+5BPVcAxwB70cE3nmra6vFqGul1at9qupoqAnixq8bMfAB4BghqH0wqjIGvvvRH4K/A+C62eYnawddWo3n3dEd3LQBWb7O8ftvGzLwtMz8JjKQ2ar+gG/W01vSXHtbU6grgaOCWavS9VDXlchy1uf11M/O9wHxqQQ3Q2TRMl9MzEfE1at8UXgK+0+PKtdIy8NVnMnM+tQOr50bE+IhYPSJWjYixEXF6tdnVwPERMbw6+HkCtSmInpgB7BERo6sDxt9rbYiI5oj4TDWX/zdqU0MtHfRxC7BFdSppU0QcCGwF/K6HNQGQmc8CY6gds2hvLWAxtTN6miLiBGDtNu2zgY1X5EyciNgC+CG1aZ0vAd+JiO16Vr1WVga++lRm/hT4FrUDsXOoTUMcQ+3MFaiF0jTgIeBhYHq1rif7+j1wbdXXf7NsSL+H2oHMl4B51ML36A76eBXYt9r2VWoj430zc25PamrX972Z2dG3l9uAW6mdqvk8tW9FbadrWi8qezUipi9vP9UU2pXAjzPzwcx8itqZPle0ngGlMoQH6SWpDI7wJakQBr4kFcLAl6RCGPiSVIiuLoBpqCHbH+PRZPVbr009p9ElSB0a3ESn90dyhC9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQTY0uQD2zYfN7ufCUf6V52NosyeTi6+/j3Kvv4oSjx7HvmG1YksmceW8y4cQrmTVnPqNHDmXGDcfz5POvAPDAw8/x9VOvWabP6846gk02GMaOn5/YiJekAt13z938+LRTWdKyhP0P+DyHfXVCo0sa0Az8ldTiliV896c3MOOJmay5+mrcf9VxTPl/T/Czy6Zw8nmTADj64DF8b8LYpcH+zMy57HLQaR3299m9t2XB23/rs/qllpYWJp56Mr+64BKam5v5woGfY8+99mbTzTZrdGkDVt2mdCLiAxFxXEScHRE/rx7/U732V5qX577BjCdmAvDW23/jiWdf5n3D38ubC/66dJvVh6xGZi63rzWGDOLrX9yb0y6cXLd6pfYeefghRo3aiA1HjWLVQYPY59PjuOvOKY0ua0CrS+BHxHHANUAADwBTq8dXR8R367HPko0eOZTtttyQqY88B8APvrYfT916CgeN3ZFTfjFp6XYbbzCMP159HLdf+A0+uv2mS9efePS+/PyKKbz9zsK+Ll0Fe2X2bNYfuf7S5RHNzcyePbuBFQ189RrhHwZ8JDNPy8wrq5/TgJ2qtg5FxISImBYR0xbPfbROpQ0sawwZxNVnHM63z7h+6ej+B+fezOZj/5Nrbp3GkQfuAdS+EWwx9gR2PfjHHHfmDVw68VDWWmMw22yxAe8fNZyb7nyokS9DBUre/e0zIhpQSTnqFfhLgPd1sH5k1dahzDw/M3fMzB2b1vtgnUobOJqa3sPVZ3yVa2+dxv+548F3tf/m1qmM//h2ACxctJh58xcA8KfHX+SZmXPZfKMR7LztJuyw1WiemHQSd1zyTTbfaAS3XfCNvnwZKlRz8/q8POvlpcuvzJ7NiBEjGljRwFevg7b/G5gSEU8BL1brRgObAcfUaZ/F+eWJh/DnZ1/m7CvvWLpu09HD+Z8X5gAwbsw2PPlc7Svyeuuuybz5C1iyJNl4g2FsNno4z86cy/THXuCC6+4FalNDN5x9JJ/66s/7/sWoOB/c+kO88MJzzJz5Is0jmpl8yyR+9JMzG13WgFaXwM/MyRGxBbUpnA2ozd/PBKZmZks99lma3bZ7P4fsuzMPP/kX/u81tcMiJ55zE4eO343NNxrBkiXJC7PmLT1DZ/cdNuM/jxrH4pYWWlqSY0+9htfeeLuRL0GFa2pq4nvfP4GjJhzOkiUtjN//ADbbbPNGlzWgRXfO4miEIdsf0z8Lk4DXpp7T6BKkDg1uotMDIV5pK0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFaOqsISJ26OqJmTm998uRJNVLp4EPnNlFWwJ793ItkqQ66jTwM3OvvixEklRfy53Dj4jVI+L4iDi/Wt48Ivatf2mSpN7UnYO2lwALgd2q5ZnAD+tWkSSpLroT+Jtm5unAIoDMfAeIulYlSep13Qn8hRExhNqBWiJiU+Bvda1KktTrujpLp9WJwGRgVET8GvgocGg9i5Ik9b7lBn5m/j4ipgO7UJvK+UZmzq17ZZKkXtWdET7AGGB3atM6qwI31q0iSVJddOe0zPOAI4GHgUeAIyLi3HoXJknqXd0Z4Y8Bts7M1oO2l1ELf0nSSqQ7Z+n8GRjdZnkU8FB9ypEk1UtXN0+7mdqc/TrA4xHxQLW8M3B/35QnSeotXU3pnNFnVUiS6q6rm6f9oS8LkSTVV3fO0tklIqZGxFsRsTAiWiLijb4oTpLUe7pz0PYc4GDgKWAIcHi1TpK0EunWhVeZ+XRErJKZLcAlEeFBW0layXQn8N+OiEHAjIg4HZgFrFHfsiRJva07UzpfqrY7BlhA7Tz8f6lnUZKk3tedm6c9Xz38K3ASQERcCxxYx7okSb2sOyP8juzaq1VIkuqup4EvSVrJRHVPtHc3ROzQ2XOA32XmyLpVBbz+TkvHhUn9wOBVV2l0CVKHBjd1/idou5rDP7OLtid6Xo4kqRE6HeE3miN89WeO8NVfdTXCdw5fkgph4EtSIQx8SSpEd+6WGRHxxYg4oVoeHRE71b80SVJv6s4I/zxqF1odXC2/CfhHzCVpJdOdm6ftnJk7RMSfADLztepmapKklUh3RviLImIVan/PlogYDiypa1WSpF7XncA/G7gRGBERpwL3AhPrWpUkqdd168KriPgA8HFqt1WYkpmP17swL7xSf+aFV+qvurrwarmBHxGjO1qfmS/8g3V1ycBXf2bgq7/q6b10Wk2iNn8fwGBgE+DPwAd7pTpJUp/ozh9A+VDb5eoumkfUrSJJUl2s8JW2mTkd+EgdapEk1dFyR/gR8a02i+8BdgDm1K0iSVJddGcOf602jxdTm9O/vj7lSJLqpcvAry64WjMzv91H9UiS6qTTOfyIaMrMFmpTOJKklVxXI/wHqIX9jIi4CbgOWNDamJk31Lk2SVIv6s4c/lDgVWBv/n4+fgIGviStRLoK/BHVGTqP8Pegb+VVsJK0kukq8FcB1oQOL9M18CVpJdNV4M/KzJP7rBJJUl11daVtpzfgkSStfLoK/I/3WRWSpLrrNPAzc15fFiJJqq8VvnmaJGnlZOBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAHwBOOfH77LPX7hx8wGeWrps//3WOPeIwDthvH4494jDeeGN+bf3rr3PU4Yey564f5ic/+mGjSpYAuO+eu/nMuE+x7z6f5KILzm90OQOegT8A7PuZ/TnrvGX/s1x+8YXsuPMuXH/zZHbceRcuv/hCAAatNogjvnYsX//WtxtRqrRUS0sLE089mfN+eSE33jSJybf8jv95+ulGlzWgGfgDwPYf3pG1115nmXV333UH4/YbD8C4/cbzhzunADBkyOpst/2HGTRotb4uU1rGIw8/xKhRG7HhqFGsOmgQ+3x6HHdV71PVh4E/QM179VXWGz4cgPWGD+e1efMaXJG0rFdmz2b9kesvXR7R3Mzs2bMbWNHA1+eBHxFf6aJtQkRMi4hpl150QV+WJamPJfmudRHRgErK0dSAfZ4EXNJRQ2aeD5wP8Po7Le9+N6jbhg4bxtw5c1hv+HDmzpnDukOHNrokaRnNzevz8qyXly6/Mns2I0aMaGBFA19dRvgR8VAnPw8DzfXYp5b1sTF7Menm3wIw6ebfsseeeze2IKmdD279IV544TlmznyRRQsXMvmWSYzZy/dpPUVm7w+kI2I28CngtfZNwP2Z+b7l9eEIv/uO/+6/M33aA7z++usMHTqMCUcdw5i9Ps5/fOebvDxrFuuPHMnEn/yMddZ5LwDjx36CBQveYtGiRay51tqc/YsLeP+mmzX2RaxkBq+6SqNLGBDuufsPnH7aRJYsaWH8/gfw1SOOanRJK73BTXQ6L1avwL8IuCQz7+2g7arM/MLy+jDw1Z8Z+Oqv+jzwe4OBr/7MwFd/1VXge1qmJBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBUiMrPRNagPRMSEzDy/0XVI7fne7DuO8MsxodEFSJ3wvdlHDHxJKoSBL0mFMPDL4Ryp+ivfm33Eg7aSVAhH+JJUCANfkgph4A9wEbFPRPw5Ip6OiO82uh6pVURcHBGvRMQjja6lFAb+ABYRqwDnAmOBrYCDI2KrxlYlLXUpsE+jiyiJgT+w7QQ8nZnPZOZC4Brgsw2uSQIgM+8G5jW6jpIY+APbBsCLbZZnVuskFcjAH9iig3WehysVysAf2GYCo9osbwi81KBaJDWYgT+wTQU2j4hNImIQcBBwU4NrktQgBv4AlpmLgWOA24DHgd9k5qONrUqqiYirgT8CW0bEzIg4rNE1DXTeWkGSCuEIX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa++rWIaImIGRHxSERcFxGr/wN9XRoRn6seX9jVjeQiYs+I2K0H+3guItbr7vpO+jg0Is7pjf1KbRn46u/eycztMnNrYCFwZNvG6o6gKywzD8/Mx7rYZE9ghQNf6s8MfK1M7gE2q0bfd0bEVcDDEbFKRPwkIqZGxEMRcQRA1JwTEY9FxCRgRGtHEXFXROxYPd4nIqZHxIMRMSUiNqb2wfLN6tvFxyJieERcX+1jakR8tHrusIi4PSL+FBG/ouP7F3UoInaKiPur594fEVu2aR4VEZOrv2VwYpvnfDEiHqjq+lVPP/BUpqZGFyB1R0Q0Ubuv/+Rq1U7A1pn5bERMAOZn5kciYjXgvoi4Hdge2BL4ENAMPAZc3K7f4cAFwB5VX0Mzc15E/BJ4KzPPqLa7CvhZZt4bEaOpXb38T8CJwL2ZeXJEjAMmrMDLeqLa7+KI+AQwETig7esD3gamVh9YC4ADgY9m5qKIOA84BLh8Bfapghn46u+GRMSM6vE9wEXUploeyMxnq/X/DGzTOj8PrANsDuwBXJ2ZLcBLEXFHB/3vAtzd2ldmdnZ/9k8AW0UsHcCvHRFrVfv4l+q5kyLitRV4besAl0XE5tTuYrpqm7bfZ+arABFxA7A7sBj4MLUPAIAhwCsrsD8VzsBXf/dOZm7XdkUVdgvargKOzczb2m33aZZ/O+joxjZQm/7cNTPf6aCWnt6f5BTgzszcv5pGuqtNW/s+s6r1ssz8Xg/3p8I5h6+B4DbgqIhYFSAitoiINYC7gYOqOf6RwF4dPPePwJiI2KR67tBq/ZvAWm22u53ajeiottuueng3tWkVImIssO4K1L0O8Jfq8aHt2j4ZEUMjYggwHrgPmAJ8LiJGtNYaERutwP5UOANfA8GF1Obnp1d/EPtX1L693gg8BTwM/AL4Q/snZuYcavPuN0TEg8C1VdPNwP6tB22BrwM7VgeFH+PvZwudBOwREdOpTS290EWdD1V3hZwZET8FTgd+FBH3Ae0Pvt4LXAHMAK7PzGnVWUXHA7dHxEPA74GR3fsVSd4tU5KK4Qhfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RC/H88VIRbI+MYAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9588594704684318\n",
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "SVM(X_test2, X_train2, Y_test2, Y_train2)\n",
    "accuracy_SVM2 = SVM.accuracy\n",
    "precision_SVM2 = SVM.precision\n",
    "model_SVM2 = SVM.SVM_model\n",
    "accuracy_tr_SVM2 = SVM.accuracy_Train\n",
    "best_C2 = SVM.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d846562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[3768    0]\n",
      " [ 160    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3768\n",
      "           1       0.00      0.00      0.00       160\n",
      "\n",
      "    accuracy                           0.96      3928\n",
      "   macro avg       0.48      0.50      0.49      3928\n",
      "weighted avg       0.92      0.96      0.94      3928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9592668024439919\n",
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "SVM(X_test3, X_train3, Y_test3, Y_train3)\n",
    "accuracy_SVM3 = SVM.accuracy\n",
    "precision_SVM3 = SVM.precision\n",
    "model_SVM3 = SVM.SVM_model\n",
    "accuracy_tr_SVM3 = SVM.accuracy_Train\n",
    "best_C3 = SVM.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbe1defc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_SVM1 = np.average( cross_val_score(model_SVM1, X_train1, Y_train1, cv=5) )\n",
    "score_SVM2 = np.average( cross_val_score(model_SVM2, X_train2, Y_train2, cv=5) )\n",
    "score_SVM3 = np.average( cross_val_score(model_SVM3, X_train3, Y_train3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9391263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy 20/80 split: 0.9572301425661914\n",
      "SVM Test Accuracy 50/50 split: 0.9588594704684318\n",
      "SVM Test Accuracy 80/20 split: 0.9592668024439919\n",
      "\n",
      "SVM Train Accuracy 20/80 split: 0.9574738986503692\n",
      "SVM Train Accuracy 50/50 split: 0.9559902200488998\n",
      "SVM Train Accuracy 80/20 split: 0.9500509683995922\n",
      "\n",
      "SVM Validation Accuracy 20/80 split: 0.9574742710815058\n",
      "SVM Validation Accuracy 50/50 split: 0.9559906895548442\n",
      "SVM Validation Accuracy 80/20 split: 0.9500517973686936\n",
      "\n",
      "SVM Accuracy 20/80 split: 0.9573927707660221\n",
      "SVM Accuracy 50/50 split: 0.956946793357392\n",
      "SVM Accuracy 80/20 split: 0.9531231894040926\n",
      "Best C: SVC(C=1e-05, kernel='linear') ,  SVC(C=1e-05, kernel='linear') ,  SVC(C=1e-05, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "print('SVM Test Accuracy 20/80 split:', accuracy_SVM1)\n",
    "print('SVM Test Accuracy 50/50 split:', accuracy_SVM2)\n",
    "print('SVM Test Accuracy 80/20 split:', accuracy_SVM3)\n",
    "print('')\n",
    "print('SVM Train Accuracy 20/80 split:', accuracy_tr_SVM1)\n",
    "print('SVM Train Accuracy 50/50 split:', accuracy_tr_SVM2)\n",
    "print('SVM Train Accuracy 80/20 split:', accuracy_tr_SVM3)\n",
    "print('')\n",
    "print('SVM Validation Accuracy 20/80 split:', score_SVM1)\n",
    "print('SVM Validation Accuracy 50/50 split:', score_SVM2)\n",
    "print('SVM Validation Accuracy 80/20 split:', score_SVM3)\n",
    "print('')\n",
    "print('SVM Accuracy 20/80 split:', (accuracy_SVM1+accuracy_tr_SVM1+score_SVM1)/3)\n",
    "print('SVM Accuracy 50/50 split:', (accuracy_SVM2+accuracy_tr_SVM2+score_SVM2)/3)\n",
    "print('SVM Accuracy 80/20 split:', (accuracy_SVM3+accuracy_tr_SVM3+score_SVM3)/3)\n",
    "print('')\n",
    "print('Best C:', best_C1,', ', best_C2,', ',best_C3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae994a87",
   "metadata": {},
   "source": [
    "## Logistic  - Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a6426ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[940   0]\n",
      " [ 42   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       940\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.96       982\n",
      "   macro avg       0.48      0.50      0.49       982\n",
      "weighted avg       0.92      0.96      0.94       982\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9572301425661914\n",
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "LOG(X_test1, X_train1, Y_test1, Y_train1)\n",
    "accuracy_log1 = LOG.accuracy\n",
    "precision_log1 = LOG.precision\n",
    "model_log1 = LOG.LOG_model\n",
    "accuracy_tr_LOG1 = LOG.accuracy_Train\n",
    "best_C1 = LOG.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5b25063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[2353    1]\n",
      " [ 101    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2354\n",
      "           1       0.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.96      2455\n",
      "   macro avg       0.48      0.50      0.49      2455\n",
      "weighted avg       0.92      0.96      0.94      2455\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9584521384928717\n",
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "LOG(X_test2, X_train2, Y_test2, Y_train2)\n",
    "accuracy_log2 = LOG.accuracy\n",
    "precision_log2 = LOG.precision\n",
    "model_log2 = LOG.LOG_model\n",
    "accuracy_tr_LOG2 = LOG.accuracy_Train\n",
    "best_C2 = LOG.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "587f4444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[3767    1]\n",
      " [ 158    2]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3768\n",
      "           1       0.67      0.01      0.02       160\n",
      "\n",
      "    accuracy                           0.96      3928\n",
      "   macro avg       0.81      0.51      0.50      3928\n",
      "weighted avg       0.95      0.96      0.94      3928\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9595213849287169\n",
      "Precision: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "LOG(X_test3, X_train3, Y_test3, Y_train3)\n",
    "accuracy_log3 = LOG.accuracy\n",
    "precision_log3 = LOG.precision\n",
    "model_log3 = LOG.LOG_model\n",
    "accuracy_tr_LOG3 = LOG.accuracy_Train\n",
    "best_C3 = LOG.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31e1b52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "score_LOG1 = np.average( cross_val_score(model_log1, X_train1, Y_train1, cv=5) )\n",
    "score_LOG2 = np.average( cross_val_score(model_log2, X_train2, Y_train2, cv=5) )\n",
    "score_LOG3 = np.average( cross_val_score(model_log3, X_train3, Y_train3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a2ca503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG Test Accuracy 20/80 split: 0.9572301425661914\n",
      "LOG Test Accuracy 50/50 split: 0.9584521384928717\n",
      "LOG Test Accuracy 80/20 split: 0.9595213849287169\n",
      "\n",
      "LOG Train Accuracy 20/80 split: 0.9572192513368984\n",
      "LOG Train Accuracy 50/50 split: 0.9563977180114099\n",
      "LOG Train Accuracy 80/20 split: 0.9500509683995922\n",
      "\n",
      "LOG Validation Accuracy 20/80 split: 0.9574745952253609\n",
      "LOG Validation Accuracy 50/50 split: 0.9559906895548445\n",
      "LOG Validation Accuracy 80/20 split: 0.9500517973686936\n",
      "\n",
      "LOG Accuracy 20/80 split: 0.9573079963761503\n",
      "LOG Accuracy 50/50 split: 0.9569468486863754\n",
      "LOG Accuracy 80/20 split: 0.9532080502323342\n",
      "\n",
      "Best C: 1.0 ,  1.0 ,  1e-05\n"
     ]
    }
   ],
   "source": [
    "print('LOG Test Accuracy 20/80 split:', accuracy_log1)\n",
    "print('LOG Test Accuracy 50/50 split:', accuracy_log2)\n",
    "print('LOG Test Accuracy 80/20 split:', accuracy_log3)\n",
    "print('')\n",
    "print('LOG Train Accuracy 20/80 split:', accuracy_tr_LOG1)\n",
    "print('LOG Train Accuracy 50/50 split:', accuracy_tr_LOG2)\n",
    "print('LOG Train Accuracy 80/20 split:', accuracy_tr_LOG3)\n",
    "print('')\n",
    "print('LOG Validation Accuracy 20/80 split:', score_LOG1)\n",
    "print('LOG Validation Accuracy 50/50 split:', score_LOG2)\n",
    "print('LOG Validation Accuracy 80/20 split:', score_LOG3)\n",
    "print('')\n",
    "print('LOG Accuracy 20/80 split:', (accuracy_log1+accuracy_tr_LOG1+score_LOG1)/3)\n",
    "print('LOG Accuracy 50/50 split:', (accuracy_log2+accuracy_tr_LOG2+score_LOG2)/3)\n",
    "print('LOG Accuracy 80/20 split:', (accuracy_log3+accuracy_tr_LOG3+score_LOG3)/3)\n",
    "print('')\n",
    "print('Best C:', best_C1,', ', best_C2,', ',best_C3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ad8d3",
   "metadata": {},
   "source": [
    "##  KNN Classification - Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ad6af00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[936   4]\n",
      " [ 40   2]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       940\n",
      "           1       0.33      0.05      0.08        42\n",
      "\n",
      "    accuracy                           0.96       982\n",
      "   macro avg       0.65      0.52      0.53       982\n",
      "weighted avg       0.93      0.96      0.94       982\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.955193482688391\n",
      "Precision: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "knn(X_test1, X_train1, Y_test1, Y_train1)\n",
    "accuracy_knn1 = knn.accuracy\n",
    "precision_knn1 = knn.precision\n",
    "model_knn1 = knn.knn_model\n",
    "accuracy_tr_knn1 = knn.accuracy_Train\n",
    "best_K1 = knn.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "398b3955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[2344   10]\n",
      " [  98    3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2354\n",
      "           1       0.23      0.03      0.05       101\n",
      "\n",
      "    accuracy                           0.96      2455\n",
      "   macro avg       0.60      0.51      0.52      2455\n",
      "weighted avg       0.93      0.96      0.94      2455\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9560081466395112\n",
      "Precision: 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "knn(X_test2, X_train2, Y_test2, Y_train2)\n",
    "accuracy_knn2 = knn.accuracy\n",
    "precision_knn2 = knn.precision\n",
    "model_knn2 = knn.knn_model\n",
    "accuracy_tr_knn2 = knn.accuracy_Train\n",
    "best_K2 = knn.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "835bc58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[3757   11]\n",
      " [ 158    2]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3768\n",
      "           1       0.15      0.01      0.02       160\n",
      "\n",
      "    accuracy                           0.96      3928\n",
      "   macro avg       0.56      0.50      0.50      3928\n",
      "weighted avg       0.93      0.96      0.94      3928\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9569755600814664\n",
      "Precision: 0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "knn(X_test3, X_train3, Y_test3, Y_train3)\n",
    "accuracy_knn3 = knn.accuracy\n",
    "precision_knn3 = knn.precision\n",
    "model_knn3 = knn.knn_model\n",
    "accuracy_tr_knn3 = knn.accuracy_Train\n",
    "best_K3 = knn.optimal_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4df0b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/jmvillal/.local/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "score_KNN1 = np.average( cross_val_score(model_knn1, X_train1, Y_train1, cv=5) )\n",
    "score_KNN2 = np.average( cross_val_score(model_knn2, X_train2, Y_train2, cv=5) )\n",
    "score_KNN3 = np.average( cross_val_score(model_knn3, X_train3, Y_train3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a727cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test Accuracy 20/80 split: 0.955193482688391\n",
      "KNN Test Accuracy 50/50 split: 0.9560081466395112\n",
      "KNN Test Accuracy 80/20 split: 0.9569755600814664\n",
      "\n",
      "KNN Train Accuracy 20/80 split: 0.9587471352177235\n",
      "KNN Train Accuracy 50/50 split: 0.9572127139364304\n",
      "KNN Train Accuracy 80/20 split: 0.9480122324159022\n",
      "\n",
      "KNN Validation Accuracy 20/80 split: 0.952635127469571\n",
      "KNN Validation Accuracy 50/50 split: 0.9515075439544454\n",
      "KNN Validation Accuracy 80/20 split: 0.9490313892054285\n",
      "\n",
      "KNN Accuracy 20/80 split: 0.9555252484585619\n",
      "KNN Accuracy 50/50 split: 0.9549094681767957\n",
      "KNN Accuracy 80/20 split: 0.9513397272342656\n",
      "\n",
      "Best K: 6 ,  6 ,  6\n"
     ]
    }
   ],
   "source": [
    "print('KNN Test Accuracy 20/80 split:', accuracy_knn1)\n",
    "print('KNN Test Accuracy 50/50 split:', accuracy_knn2)\n",
    "print('KNN Test Accuracy 80/20 split:', accuracy_knn3)\n",
    "print('')\n",
    "print('KNN Train Accuracy 20/80 split:', accuracy_tr_knn1)\n",
    "print('KNN Train Accuracy 50/50 split:', accuracy_tr_knn2)\n",
    "print('KNN Train Accuracy 80/20 split:', accuracy_tr_knn3)\n",
    "print('')\n",
    "print('KNN Validation Accuracy 20/80 split:', score_KNN1)\n",
    "print('KNN Validation Accuracy 50/50 split:', score_KNN2)\n",
    "print('KNN Validation Accuracy 80/20 split:', score_KNN3)\n",
    "print('')\n",
    "print('KNN Accuracy 20/80 split:', (accuracy_knn1+accuracy_tr_knn1+score_KNN1)/3)\n",
    "print('KNN Accuracy 50/50 split:', (accuracy_knn2+accuracy_tr_knn2+score_KNN2)/3)\n",
    "print('KNN Accuracy 80/20 split:', (accuracy_knn3+accuracy_tr_knn3+score_KNN3)/3)\n",
    "print('')\n",
    "print('Best K:', best_K1,', ', best_K2,', ',best_K3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f4323",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron  - Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae42ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test1, X_train1, Y_test1, Y_train1)\n",
    "accuracy_mlp1 = MLP.accuracy\n",
    "precision_mlp1 = MLP.precision\n",
    "model_mlp1 = MLP.MLP_model\n",
    "accuracy_tr_MLP1 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test2, X_train2, Y_test2, Y_train2)\n",
    "accuracy_mlp2 = MLP.accuracy\n",
    "precision_mlp2 = MLP.precision\n",
    "model_mlp2 = MLP.MLP_model\n",
    "accuracy_tr_MLP2 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test3, X_train3, Y_test3, Y_train3)\n",
    "accuracy_mlp3 = MLP.accuracy\n",
    "precision_mlp3 = MLP.precision\n",
    "model_mlp3 = MLP.MLP_model\n",
    "accuracy_tr_MLP3 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3088620",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_MLP1 = np.average( cross_val_score(model_mlp1, X_train1, Y_train1, cv=5) )\n",
    "score_MLP2 = np.average( cross_val_score(model_mlp2, X_train2, Y_train2, cv=5) )\n",
    "score_MLP3 = np.average( cross_val_score(model_mlp3, X_train3, Y_train3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MLP Test Accuracy 20/80 split:', accuracy_mlp1)\n",
    "print('MLP Test Accuracy 50/50 split:', accuracy_mlp2)\n",
    "print('MLP Test Accuracy 80/20 split:', accuracy_mlp3)\n",
    "print('')\n",
    "print('MLP Train Accuracy 20/80 split:', accuracy_tr_MLP1)\n",
    "print('MLP Train Accuracy 50/50 split:', accuracy_tr_MLP2)\n",
    "print('MLP Train Accuracy 80/20 split:', accuracy_tr_MLP3)\n",
    "print('')\n",
    "print('MLP Validation Accuracy 20/80 split:', score_MLP1)\n",
    "print('MLP Validation Accuracy 50/50 split:', score_MLP2)\n",
    "print('MLP Validation Accuracy 80/20 split:', score_MLP3)\n",
    "print('')\n",
    "print('MLP Accuracy 20/80 split:', (accuracy_mlp1+accuracy_tr_MLP1+score_MLP1)/3)\n",
    "print('MLP Accuracy 50/50 split:', (accuracy_mlp2+accuracy_tr_MLP2+score_MLP2)/3)\n",
    "print('MLP Accuracy 80/20 split:', (accuracy_mlp3+accuracy_tr_MLP3+score_MLP3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5408707c",
   "metadata": {},
   "source": [
    "# Heart Disease Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the csv file into a data frame\n",
    "heart_df = pd.read_csv('Datasets/Heart/processed.cleveland.data')\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping slope and cheast pain\n",
    "heart_df = heart_df.drop(['slope','cp'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming certain columns\n",
    "heart_df.rename(columns = {'trestbps':'rest_bps','fbs':'fasting_blodd_sugar',\n",
    "                          'restecg':'rest_ecg','thalach':'max_heart_rate',\n",
    "                          'exang':'excerise_induced_ang','ca':'num_major_vessicals',\n",
    "                          'num':'Diagnostic'}, inplace = True) \n",
    "heart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d383db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the sum of null inputs\n",
    "heart_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f969ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking for unique inputs\n",
    "unique_values_in_columns(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a298dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new data frame that does not have ? \n",
    "heart_df = heart_df[heart_df != \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at null sum\n",
    "heart_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef076d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping null\n",
    "heart_df = heart_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#description of data\n",
    "heart_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chaning the values of 1,2,3,4 into 1 since 1,2,3,4 are all heart disease\n",
    "#but just want to look at if there is a heart problem\n",
    "heart_df[\"Diagnostic\"] = heart_df[\"Diagnostic\"].map({0:0,1: 1, 2: 1,3:1,4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ef3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at unique vlaues of diagonstic to see if any changes need to be made\n",
    "heart_df[\"Diagnostic\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the Diagnosstic \n",
    "abel_encoder = LabelEncoder().fit(heart_df[\"Diagnostic\"])\n",
    "heart_df[\"Diagnostic\"] = label_encoder.transform(heart_df[\"Diagnostic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Data to a numpy Array\n",
    "\n",
    "heart_np = heart_df.values\n",
    "\n",
    "\n",
    "#Preview of the first 5 rows\n",
    "\n",
    "print(heart_np[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a15c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_heart =  heart_np[:,:11]\n",
    "Y_heart = heart_np[:,11:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaeb6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_and_Y_heart = np.hstack((X_heart, Y_heart))            \n",
    "np.random.shuffle(X_and_Y_heart)     \n",
    "\n",
    "print(X_heart.shape)\n",
    "print(Y_heart.shape)\n",
    "print(X_and_Y_heart[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "X_shuffled_heart = X_and_Y_heart[:,:11]\n",
    "Y_shuffled_heart = X_and_Y_heart[:,11:]\n",
    "\n",
    "print (X_shuffled_heart.shape)\n",
    "print(Y_shuffled_heart.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5731c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data and turing it into int\n",
    "\n",
    "X_train_heart1, X_test_heart1, Y_train_heart1, Y_test_heart1 = train_test_split(X_shuffled_heart,\n",
    "                                                        Y_shuffled_heart, test_size=0.2, random_state=42)\n",
    "Y_train_heart1= Y_train_heart1.astype('int')\n",
    "Y_test_heart1 = Y_test_heart1.astype('int')\n",
    "\n",
    "X_train_heart2, X_test_heart2, Y_train_heart2, Y_test_heart2 = train_test_split(X_shuffled_heart,\n",
    "                                                        Y_shuffled_heart, test_size=0.5, random_state=42)\n",
    "Y_train_heart2= Y_train_heart2.astype('int')\n",
    "Y_test_heart2 = Y_test_heart2.astype('int')\n",
    "\n",
    "\n",
    "X_train_heart3, X_test_heart3, Y_train_heart3, Y_test_heart3 = train_test_split(X_shuffled_heart,\n",
    "                                                        Y_shuffled_heart, test_size=0.8, random_state=42)\n",
    "Y_train_heart3= Y_train_heart3.astype('int')\n",
    "Y_test_heart3 = Y_test_heart3.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bbbba7",
   "metadata": {},
   "source": [
    "## Decision tree Classifier - Heart Diesease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ea8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_heart1, X_train_heart1, Y_test_heart1, Y_train_heart1)\n",
    "accuracy_DTHT1 = DT.accuracy\n",
    "DT_precision1 = DT.precision\n",
    "model_DTHT1 = DT.DT_model\n",
    "accuracy_tr_DTHT1 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_heart2, X_train_heart2, Y_test_heart2, Y_train_heart2)\n",
    "accuracy_DTHT2 = DT.accuracy\n",
    "DT_precision2 = DT.precision\n",
    "model_DTHT2 = DT.DT_model\n",
    "accuracy_tr_DTHT2 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8224ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_heart3, X_train_heart3, Y_test_heart3, Y_train_heart3)\n",
    "accuracy_DTHT3 = DT.accuracy\n",
    "DT_precision3 = DT.precision\n",
    "model_DTHT3 = DT.DT_model\n",
    "accuracy_tr_DTHT3 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_DTHT1 = np.average( cross_val_score(model_DTHT1, X_train_heart1, Y_train_heart1, cv=5) )\n",
    "score_DTHT2 = np.average( cross_val_score(model_DTHT2, X_train_heart1, Y_train_heart1, cv=5) )\n",
    "score_DTHT3 = np.average( cross_val_score(model_DTHT3, X_train_heart1, Y_train_heart1, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DT Test Accuracy 20/80 split:', accuracy_DTHT1)\n",
    "print('DT Test Accuracy 50/50 split:', accuracy_DTHT2)\n",
    "print('DT Test Accuracy 80/20 split:', accuracy_DTHT3)\n",
    "print('')\n",
    "print('DT Train Accuracy 20/80 split:', accuracy_tr_DTHT1)\n",
    "print('DT Train Accuracy 50/50 split:', accuracy_tr_DTHT2)\n",
    "print('DT Train Accuracy 80/20 split:', accuracy_tr_DTHT3)\n",
    "print('')\n",
    "print('DT Validation Accuracy 20/80 split:', score_DTHT1)\n",
    "print('DT Validation Accuracy 50/50 split:', score_DTHT2)\n",
    "print('DT Validation Accuracy 80/20 split:', score_DTHT3)\n",
    "print('')\n",
    "print('DT Accuracy 20/80 split:', (accuracy_DTHT1+accuracy_tr_DTHT1+score_DTHT1)/3)\n",
    "print('DT Accuracy 50/50 split:', (accuracy_DTHT2+accuracy_tr_DTHT2+score_DTHT2)/3)\n",
    "print('DT Accuracy 80/20 split:', (accuracy_DTHT3+accuracy_tr_DTHT3+score_DTHT3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981ddbe",
   "metadata": {},
   "source": [
    "## SVM - Heart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49472626",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_heart1, X_train_heart1, Y_test_heart1, Y_train_heart1)\n",
    "accuracy_SVMHT1 = SVM.accuracy\n",
    "precision_SVM1 = SVM.precision\n",
    "model_SVMHT1 = SVM.SVM_model\n",
    "accuracy_tr_SVMHT1 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_heart2, X_train_heart2, Y_test_heart2, Y_train_heart2)\n",
    "accuracy_SVMHT2 = SVM.accuracy\n",
    "precision_SVM2 = SVM.precision\n",
    "model_SVMHT2 = SVM.SVM_model\n",
    "accuracy_tr_SVMHT2 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54161c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_heart3, X_train_heart3, Y_test_heart3, Y_train_heart3)\n",
    "accuracy_SVMHT3 = SVM.accuracy\n",
    "precision_SVM3 = SVM.precision\n",
    "model_SVMHT3 = SVM.SVM_model\n",
    "accuracy_tr_SVMHT3 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_SVMHT1 = np.average( cross_val_score(model_SVMHT1, X_train_heart1, Y_train_heart1, cv=5) )\n",
    "score_SVMHT2 = np.average( cross_val_score(model_SVMHT2, X_train_heart2, Y_train_heart2, cv=5) )\n",
    "score_SVMHT3 = np.average( cross_val_score(model_SVMHT3, X_train_heart3, Y_train_heart3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0112a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM Test Accuracy 20/80 split:', accuracy_SVMHT1)\n",
    "print('SVM Test Accuracy 50/50 split:', accuracy_SVMHT2)\n",
    "print('SVM Test Accuracy 80/20 split:', accuracy_SVMHT3)\n",
    "print('')\n",
    "print('SVM Train Accuracy 20/80 split:', accuracy_tr_SVMHT1)\n",
    "print('SVM Train Accuracy 50/50 split:', accuracy_tr_SVMHT2)\n",
    "print('SVM Train Accuracy 80/20 split:', accuracy_tr_SVMHT3)\n",
    "print('')\n",
    "print('SVM Validation Accuracy 20/80 split:', score_SVMHT1)\n",
    "print('SVM Validation Accuracy 50/50 split:', score_SVMHT2)\n",
    "print('SVM Validation Accuracy 80/20 split:', score_SVMHT3)\n",
    "print('')\n",
    "print('SVM Accuracy 20/80 split:', (accuracy_SVMHT1+accuracy_tr_SVMHT1+score_SVMHT1)/3)\n",
    "print('SVM Accuracy 50/50 split:', (accuracy_SVMHT2+accuracy_tr_SVMHT2+score_SVMHT2)/3)\n",
    "print('SVM Accuracy 80/20 split:', (accuracy_SVMHT3+accuracy_tr_SVMHT3+score_SVMHT3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d0c1a",
   "metadata": {},
   "source": [
    "## Log - Heart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_heart1, X_train_heart1, Y_test_heart1, Y_train_heart1)\n",
    "accuracy_logHT1 = LOG.accuracy\n",
    "precision_log1 = LOG.precision\n",
    "model_logHT1 = LOG.LOG_model\n",
    "accuracy_tr_LOGHT1 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0009c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_heart2, X_train_heart2, Y_test_heart2, Y_train_heart2)\n",
    "accuracy_logHT2 = LOG.accuracy\n",
    "precision_log2 = LOG.precision\n",
    "model_logHT2 = LOG.LOG_model\n",
    "accuracy_tr_LOGHT2 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_heart3, X_train_heart3, Y_test_heart3, Y_train_heart3)\n",
    "accuracy_logHT3 = LOG.accuracy\n",
    "precision_log3 = LOG.precision\n",
    "model_logHT3 = LOG.LOG_model\n",
    "accuracy_tr_LOGHT3 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e739f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LOGHT1 = np.average( cross_val_score(model_logHT1, X_train_heart1, Y_train_heart1, cv=5) )\n",
    "score_LOGHT2 = np.average( cross_val_score(model_logHT2, X_train_heart2, Y_train_heart2, cv=5) )\n",
    "score_LOGHT3 = np.average( cross_val_score(model_logHT3, X_train_heart3, Y_train_heart3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LOG Test Accuracy 20/80 split:', accuracy_logHT1)\n",
    "print('LOG Test Accuracy 50/50 split:', accuracy_logHT2)\n",
    "print('LOG Test Accuracy 80/20 split:', accuracy_log3)\n",
    "print('')\n",
    "print('LOG Train Accuracy 20/80 split:', accuracy_tr_LOGHT1)\n",
    "print('LOG Train Accuracy 50/50 split:', accuracy_tr_LOGHT2)\n",
    "print('LOG Train Accuracy 80/20 split:', accuracy_tr_LOGHT3)\n",
    "print('')\n",
    "print('LOG Validation Accuracy 20/80 split:', score_LOGHT1)\n",
    "print('LOG Validation Accuracy 50/50 split:', score_LOGHT2)\n",
    "print('LOG Validation Accuracy 80/20 split:', score_LOGHT3)\n",
    "print('')\n",
    "print('LOG Accuracy 20/80 split:', (accuracy_logHT1+accuracy_tr_LOGHT1+score_LOGHT1)/3)\n",
    "print('LOG Accuracy 50/50 split:', (accuracy_logHT2+accuracy_tr_LOGHT2+score_LOGHT2)/3)\n",
    "print('LOG Accuracy 80/20 split:', (accuracy_logHT3+accuracy_tr_LOGHT3+score_LOGHT3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc99543",
   "metadata": {},
   "source": [
    "## KNN - Heart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_heart1, X_train_heart1, Y_test_heart1, Y_train_heart1)\n",
    "knn_accuracyHT1 = knn.accuracy\n",
    "knn_precision1 = knn.precision\n",
    "model_knnHT1 = knn.knn_model\n",
    "accuracy_tr_knnHT1 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_heart2, X_train_heart2, Y_test_heart2, Y_train_heart2)\n",
    "knn_accuracyHT2 = knn.accuracy\n",
    "knn_precision2 = knn.precision\n",
    "model_knnHT2 = knn.knn_model\n",
    "accuracy_tr_knnHT2 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86655627",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_heart3, X_train_heart3, Y_test_heart3, Y_train_heart3)\n",
    "knn_accuracyHT3 = knn.accuracy\n",
    "knn_precision3 = knn.precision\n",
    "model_knnHT3 = knn.knn_model\n",
    "accuracy_tr_knnHT3 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1174b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_KNNHT1 = np.average( cross_val_score(model_knnHT1, X_train_heart1, Y_train_heart1, cv=5) )\n",
    "score_KNNHT2 = np.average( cross_val_score(model_knnHT2, X_train_heart2, Y_train_heart2, cv=5) )\n",
    "score_KNNHT3 = np.average( cross_val_score(model_knnHT3, X_train_heart3, Y_train_heart3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c02e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN Test Accuracy 20/80 split:', knn_accuracyHT1)\n",
    "print('KNN Test Accuracy 50/50 split:', knn_accuracyHT2)\n",
    "print('KNN Test Accuracy 80/20 split:', knn_accuracyHT3)\n",
    "print('')\n",
    "print('KNN Train Accuracy 20/80 split:', accuracy_tr_knnHT1)\n",
    "print('KNN Train Accuracy 50/50 split:', accuracy_tr_knnHT2)\n",
    "print('KNN Train Accuracy 80/20 split:', accuracy_tr_knnHT3)\n",
    "print('')\n",
    "print('KNN Validation Accuracy 20/80 split:', score_KNNHT1)\n",
    "print('KNN Validation Accuracy 50/50 split:', score_KNNHT2)\n",
    "print('KNN Validation Accuracy 80/20 split:', score_KNNHT3)\n",
    "print('')\n",
    "print('KNN Accuracy 20/80 split:', (knn_accuracyHT1+accuracy_tr_knnHT1+score_KNNHT1)/3)\n",
    "print('KNN Accuracy 50/50 split:', (knn_accuracyHT2+accuracy_tr_knnHT2+score_KNNHT2)/3)\n",
    "print('KNN Accuracy 80/20 split:', (knn_accuracyHT3+accuracy_tr_knnHT3+score_KNNHT3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d80ad",
   "metadata": {},
   "source": [
    "## Multi layer perceptron - Heart Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2234ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_heart1, X_train_heart1, Y_test_heart1, Y_train_heart1)\n",
    "accuracy_mlpHT1 = MLP.accuracy\n",
    "MLP_precision1 = MLP.precision\n",
    "model_mlpHT1 = MLP.MLP_model\n",
    "accuracy_tr_MLPHT1 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_heart2, X_train_heart2, Y_test_heart2, Y_train_heart2)\n",
    "accuracy_mlpHT2 = MLP.accuracy\n",
    "MLP_precision2 = MLP.precision\n",
    "model_mlpHT2 = MLP.MLP_model\n",
    "accuracy_tr_MLPHT2 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_heart3, X_train_heart3, Y_test_heart3, Y_train_heart3)\n",
    "accuracy_mlpHT3 = MLP.accuracy\n",
    "MLP_precision3 = MLP.precision\n",
    "model_mlpHT3 = MLP.MLP_model\n",
    "accuracy_tr_MLPHT3 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_MLPHT1 = np.average( cross_val_score(model_mlpHT1, X_train_heart1, Y_train_heart1, cv=5) )\n",
    "score_MLPHT2 = np.average( cross_val_score(model_mlpHT2, X_train_heart2, Y_train_heart2, cv=5) )\n",
    "score_MLPHT3 = np.average( cross_val_score(model_mlpHT3, X_train_heart3, Y_train_heart3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10330cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MLP Test Accuracy 20/80 split:', accuracy_mlpHT1)\n",
    "print('MLP Test Accuracy 50/50 split:', accuracy_mlpHT2)\n",
    "print('MLP Test Accuracy 80/20 split:', accuracy_mlpHT3)\n",
    "print('')\n",
    "print('MLP Train Accuracy 20/80 split:', accuracy_tr_MLP1)\n",
    "print('MLP Train Accuracy 50/50 split:', accuracy_tr_MLP2)\n",
    "print('MLP Train Accuracy 80/20 split:', accuracy_tr_MLP3)\n",
    "print('')\n",
    "print('MLP Validation Accuracy 20/80 split:', score_MLP1)\n",
    "print('MLP Validation Accuracy 50/50 split:', score_MLP2)\n",
    "print('MLP Validation Accuracy 80/20 split:', score_MLP3)\n",
    "print('')\n",
    "print('MLP Accuracy 20/80 split:', (accuracy_mlpHT1+accuracy_tr_MLPHT1+score_MLPHT1)/3)\n",
    "print('MLP Accuracy 50/50 split:', (accuracy_mlpHT2+accuracy_tr_MLPHT2+score_MLPHT2)/3)\n",
    "print('MLP Accuracy 80/20 split:', (accuracy_mlpHT3+accuracy_tr_MLPHT3+score_MLPHT3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543e2f7",
   "metadata": {},
   "source": [
    "# Adult Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7887168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                  1       2            3   4                    5   \\\n",
       "0      39          State-gov   77516    Bachelors  13        Never-married   \n",
       "1      50   Self-emp-not-inc   83311    Bachelors  13   Married-civ-spouse   \n",
       "2      38            Private  215646      HS-grad   9             Divorced   \n",
       "3      53            Private  234721         11th   7   Married-civ-spouse   \n",
       "4      28            Private  338409    Bachelors  13   Married-civ-spouse   \n",
       "...    ..                ...     ...          ...  ..                  ...   \n",
       "32556  27            Private  257302   Assoc-acdm  12   Married-civ-spouse   \n",
       "32557  40            Private  154374      HS-grad   9   Married-civ-spouse   \n",
       "32558  58            Private  151910      HS-grad   9              Widowed   \n",
       "32559  22            Private  201490      HS-grad   9        Never-married   \n",
       "32560  52       Self-emp-inc  287927      HS-grad   9   Married-civ-spouse   \n",
       "\n",
       "                       6               7       8        9      10  11  12  \\\n",
       "0            Adm-clerical   Not-in-family   White     Male   2174   0  40   \n",
       "1         Exec-managerial         Husband   White     Male      0   0  13   \n",
       "2       Handlers-cleaners   Not-in-family   White     Male      0   0  40   \n",
       "3       Handlers-cleaners         Husband   Black     Male      0   0  40   \n",
       "4          Prof-specialty            Wife   Black   Female      0   0  40   \n",
       "...                   ...             ...     ...      ...    ...  ..  ..   \n",
       "32556        Tech-support            Wife   White   Female      0   0  38   \n",
       "32557   Machine-op-inspct         Husband   White     Male      0   0  40   \n",
       "32558        Adm-clerical       Unmarried   White   Female      0   0  40   \n",
       "32559        Adm-clerical       Own-child   White     Male      0   0  20   \n",
       "32560     Exec-managerial            Wife   White   Female  15024   0  40   \n",
       "\n",
       "                   13      14  \n",
       "0       United-States   <=50K  \n",
       "1       United-States   <=50K  \n",
       "2       United-States   <=50K  \n",
       "3       United-States   <=50K  \n",
       "4                Cuba   <=50K  \n",
       "...               ...     ...  \n",
       "32556   United-States   <=50K  \n",
       "32557   United-States    >50K  \n",
       "32558   United-States   <=50K  \n",
       "32559   United-States   <=50K  \n",
       "32560   United-States    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dat frame with no header (column names)\n",
    "Adult_df = pd.read_csv('Datasets/Adult_income/adult.data', header = None)\n",
    "Adult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53fd4ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>captial-gain</th>\n",
       "      <th>captial-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  captial-gain  captial-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the colmns names\n",
    "Adult_df.columns = ['age','workclass','fnlwgt','education',\n",
    "                    'education-num','marital-status','occupation',\n",
    "                    'relationship','race','sex','captial-gain',\n",
    "                   'captial-loss','hours-per-week','native-country','income']\n",
    "Adult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f910bd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>captial-gain</th>\n",
       "      <th>captial-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29166</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29167</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29168</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29169</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29170 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       37            Private  284582      Masters             14   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "29165   27            Private  257302   Assoc-acdm             12   \n",
       "29166   40            Private  154374      HS-grad              9   \n",
       "29167   58            Private  151910      HS-grad              9   \n",
       "29168   22            Private  201490      HS-grad              9   \n",
       "29169   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "...                    ...                 ...             ...     ...   \n",
       "29165   Married-civ-spouse        Tech-support            Wife   White   \n",
       "29166   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "29167              Widowed        Adm-clerical       Unmarried   White   \n",
       "29168        Never-married        Adm-clerical       Own-child   White   \n",
       "29169   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  captial-gain  captial-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40   United-States   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "29165   Female             0             0              38   United-States   \n",
       "29166     Male             0             0              40   United-States   \n",
       "29167   Female             0             0              40   United-States   \n",
       "29168     Male             0             0              20   United-States   \n",
       "29169   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "29165   <=50K  \n",
       "29166    >50K  \n",
       "29167   <=50K  \n",
       "29168   <=50K  \n",
       "29169    >50K  \n",
       "\n",
       "[29170 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only want to look at US data\n",
    "# Converting a Dataframe the only has US in the Native-country column\n",
    "\n",
    "Adult_df = Adult_df[Adult_df['native-country'] == ' United-States'].reset_index(drop = True)\n",
    "Adult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15bd005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29170 entries, 0 to 29169\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   workclass       29170 non-null  object\n",
      " 1   education       29170 non-null  object\n",
      " 2   education-num   29170 non-null  int64 \n",
      " 3   marital-status  29170 non-null  object\n",
      " 4   occupation      29170 non-null  object\n",
      " 5   relationship    29170 non-null  object\n",
      " 6   race            29170 non-null  object\n",
      " 7   sex             29170 non-null  object\n",
      " 8   native-country  29170 non-null  object\n",
      " 9   income          29170 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 2.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'workclass': [' State-gov',\n",
       "   ' Self-emp-not-inc',\n",
       "   ' Private',\n",
       "   ' Federal-gov',\n",
       "   ' Local-gov',\n",
       "   ' Self-emp-inc',\n",
       "   ' ?',\n",
       "   ' Without-pay',\n",
       "   ' Never-worked'],\n",
       "  'education': [' Bachelors',\n",
       "   ' HS-grad',\n",
       "   ' 11th',\n",
       "   ' Masters',\n",
       "   ' Some-college',\n",
       "   ' Assoc-acdm',\n",
       "   ' Doctorate',\n",
       "   ' 9th',\n",
       "   ' Assoc-voc',\n",
       "   ' 10th',\n",
       "   ' 7th-8th',\n",
       "   ' Prof-school',\n",
       "   ' 1st-4th',\n",
       "   ' Preschool',\n",
       "   ' 5th-6th',\n",
       "   ' 12th'],\n",
       "  'education-num': [13, 9, 7, 14, 10, 12, 16, 5, 11, 6, 4, 15, 2, 1, 3, 8],\n",
       "  'marital-status': [' Never-married',\n",
       "   ' Married-civ-spouse',\n",
       "   ' Divorced',\n",
       "   ' Separated',\n",
       "   ' Married-AF-spouse',\n",
       "   ' Widowed',\n",
       "   ' Married-spouse-absent'],\n",
       "  'occupation': [' Adm-clerical',\n",
       "   ' Exec-managerial',\n",
       "   ' Handlers-cleaners',\n",
       "   ' Prof-specialty',\n",
       "   ' Sales',\n",
       "   ' Farming-fishing',\n",
       "   ' Machine-op-inspct',\n",
       "   ' Other-service',\n",
       "   ' Transport-moving',\n",
       "   ' Tech-support',\n",
       "   ' Craft-repair',\n",
       "   ' Protective-serv',\n",
       "   ' ?',\n",
       "   ' Armed-Forces',\n",
       "   ' Priv-house-serv'],\n",
       "  'relationship': [' Not-in-family',\n",
       "   ' Husband',\n",
       "   ' Wife',\n",
       "   ' Own-child',\n",
       "   ' Unmarried',\n",
       "   ' Other-relative'],\n",
       "  'race': [' White',\n",
       "   ' Black',\n",
       "   ' Other',\n",
       "   ' Asian-Pac-Islander',\n",
       "   ' Amer-Indian-Eskimo'],\n",
       "  'sex': [' Male', ' Female'],\n",
       "  'native-country': [' United-States'],\n",
       "  'income': [' <=50K', ' >50K']},\n",
       " None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the unique values the do  not include the droped columns\n",
    "unique_values_in_columns(Adult_df.drop(['age', 'captial-gain', \n",
    "                                        'captial-loss','hours-per-week','fnlwgt'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e28adb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>captial-gain</th>\n",
       "      <th>captial-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29166</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29167</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29168</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29169</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27504 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       37            Private  284582      Masters             14   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "29165   27            Private  257302   Assoc-acdm             12   \n",
       "29166   40            Private  154374      HS-grad              9   \n",
       "29167   58            Private  151910      HS-grad              9   \n",
       "29168   22            Private  201490      HS-grad              9   \n",
       "29169   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "...                    ...                 ...             ...     ...   \n",
       "29165   Married-civ-spouse        Tech-support            Wife   White   \n",
       "29166   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "29167              Widowed        Adm-clerical       Unmarried   White   \n",
       "29168        Never-married        Adm-clerical       Own-child   White   \n",
       "29169   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  captial-gain  captial-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40   United-States   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "29165   Female             0             0              38   United-States   \n",
       "29166     Male             0             0              40   United-States   \n",
       "29167   Female             0             0              40   United-States   \n",
       "29168     Male             0             0              20   United-States   \n",
       "29169   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "29165   <=50K  \n",
       "29166    >50K  \n",
       "29167   <=50K  \n",
       "29168   <=50K  \n",
       "29169    >50K  \n",
       "\n",
       "[27504 rows x 15 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting rid of null inputs that were placed as ? by creating a new data frame\n",
    "\n",
    "Adult_df1 = Adult_df[Adult_df[\"workclass\"] != \" ?\"]\n",
    "Adult_df2 = Adult_df1[Adult_df1['occupation'] != ' ?']\n",
    "Adult_df = Adult_df2\n",
    "Adult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26d8abef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165</th>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29166</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29167</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29168</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29169</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27504 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               workclass    education       marital-status  \\\n",
       "0              State-gov    Bachelors        Never-married   \n",
       "1       Self-emp-not-inc    Bachelors   Married-civ-spouse   \n",
       "2                Private      HS-grad             Divorced   \n",
       "3                Private         11th   Married-civ-spouse   \n",
       "4                Private      Masters   Married-civ-spouse   \n",
       "...                  ...          ...                  ...   \n",
       "29165            Private   Assoc-acdm   Married-civ-spouse   \n",
       "29166            Private      HS-grad   Married-civ-spouse   \n",
       "29167            Private      HS-grad              Widowed   \n",
       "29168            Private      HS-grad        Never-married   \n",
       "29169       Self-emp-inc      HS-grad   Married-civ-spouse   \n",
       "\n",
       "               occupation    relationship    race      sex  hours-per-week  \\\n",
       "0            Adm-clerical   Not-in-family   White     Male              40   \n",
       "1         Exec-managerial         Husband   White     Male              13   \n",
       "2       Handlers-cleaners   Not-in-family   White     Male              40   \n",
       "3       Handlers-cleaners         Husband   Black     Male              40   \n",
       "4         Exec-managerial            Wife   White   Female              40   \n",
       "...                   ...             ...     ...      ...             ...   \n",
       "29165        Tech-support            Wife   White   Female              38   \n",
       "29166   Machine-op-inspct         Husband   White     Male              40   \n",
       "29167        Adm-clerical       Unmarried   White   Female              40   \n",
       "29168        Adm-clerical       Own-child   White     Male              20   \n",
       "29169     Exec-managerial            Wife   White   Female              40   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "29165   <=50K  \n",
       "29166    >50K  \n",
       "29167   <=50K  \n",
       "29168   <=50K  \n",
       "29169    >50K  \n",
       "\n",
       "[27504 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping these columns\n",
    "Adult_df = Adult_df.drop(['age','fnlwgt','education-num','captial-gain','captial-loss','native-country'], axis = 1)\n",
    "Adult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0dda103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27504.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.970986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.041120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hours-per-week\n",
       "count    27504.000000\n",
       "mean        40.970986\n",
       "std         12.041120\n",
       "min          1.000000\n",
       "25%         40.000000\n",
       "50%         40.000000\n",
       "75%         45.000000\n",
       "max         99.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adult_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84ee50d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Federal-gov</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-emp-inc</th>\n",
       "      <th>Self-emp-not-inc</th>\n",
       "      <th>State-gov</th>\n",
       "      <th>Without-pay</th>\n",
       "      <th>10th</th>\n",
       "      <th>11th</th>\n",
       "      <th>12th</th>\n",
       "      <th>...</th>\n",
       "      <th>Wife</th>\n",
       "      <th>Amer-Indian-Eskimo</th>\n",
       "      <th>Asian-Pac-Islander</th>\n",
       "      <th>Black</th>\n",
       "      <th>Other</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29166</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29167</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29168</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29169</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27504 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Federal-gov   Local-gov   Private   Self-emp-inc   Self-emp-not-inc  \\\n",
       "0             False       False     False          False              False   \n",
       "1             False       False     False          False               True   \n",
       "2             False       False      True          False              False   \n",
       "3             False       False      True          False              False   \n",
       "4             False       False      True          False              False   \n",
       "...             ...         ...       ...            ...                ...   \n",
       "29165         False       False      True          False              False   \n",
       "29166         False       False      True          False              False   \n",
       "29167         False       False      True          False              False   \n",
       "29168         False       False      True          False              False   \n",
       "29169         False       False     False           True              False   \n",
       "\n",
       "        State-gov   Without-pay   10th   11th   12th  ...   Wife  \\\n",
       "0            True         False  False  False  False  ...  False   \n",
       "1           False         False  False  False  False  ...  False   \n",
       "2           False         False  False  False  False  ...  False   \n",
       "3           False         False  False   True  False  ...  False   \n",
       "4           False         False  False  False  False  ...   True   \n",
       "...           ...           ...    ...    ...    ...  ...    ...   \n",
       "29165       False         False  False  False  False  ...   True   \n",
       "29166       False         False  False  False  False  ...  False   \n",
       "29167       False         False  False  False  False  ...  False   \n",
       "29168       False         False  False  False  False  ...  False   \n",
       "29169       False         False  False  False  False  ...   True   \n",
       "\n",
       "        Amer-Indian-Eskimo   Asian-Pac-Islander   Black   Other   White  \\\n",
       "0                    False                False   False   False    True   \n",
       "1                    False                False   False   False    True   \n",
       "2                    False                False   False   False    True   \n",
       "3                    False                False    True   False   False   \n",
       "4                    False                False   False   False    True   \n",
       "...                    ...                  ...     ...     ...     ...   \n",
       "29165                False                False   False   False    True   \n",
       "29166                False                False   False   False    True   \n",
       "29167                False                False   False   False    True   \n",
       "29168                False                False   False   False    True   \n",
       "29169                False                False   False   False    True   \n",
       "\n",
       "        Female   Male  hours-per-week  income  \n",
       "0        False   True              40   <=50K  \n",
       "1        False   True              13   <=50K  \n",
       "2        False   True              40   <=50K  \n",
       "3        False   True              40   <=50K  \n",
       "4         True  False              40   <=50K  \n",
       "...        ...    ...             ...     ...  \n",
       "29165     True  False              38   <=50K  \n",
       "29166    False   True              40    >50K  \n",
       "29167     True  False              40   <=50K  \n",
       "29168    False   True              20   <=50K  \n",
       "29169     True  False              40    >50K  \n",
       "\n",
       "[27504 rows x 59 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the encoding these columns\n",
    "workclass_encoded = pd.get_dummies(Adult_df['workclass'])\n",
    "education_encoded = pd.get_dummies(Adult_df['education'])\n",
    "married_encoded = pd.get_dummies(Adult_df['marital-status'])\n",
    "job_encoded =  pd.get_dummies(Adult_df['occupation'])\n",
    "relationship_encoded = pd.get_dummies(Adult_df['relationship'])\n",
    "race_encoded = pd.get_dummies(Adult_df['race'])\n",
    "sex_encoded = pd.get_dummies(Adult_df['sex'])\n",
    "income_encoded = pd.get_dummies(Adult_df['income'])\n",
    "\n",
    "Adult_df = pd.concat([workclass_encoded, education_encoded, married_encoded,\n",
    "                      job_encoded, relationship_encoded, race_encoded, sex_encoded,\n",
    "                      Adult_df['hours-per-week'],Adult_df['income']], axis =1 )\n",
    "\n",
    "Adult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efa1b5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Federal-gov</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-emp-inc</th>\n",
       "      <th>Self-emp-not-inc</th>\n",
       "      <th>State-gov</th>\n",
       "      <th>Without-pay</th>\n",
       "      <th>10th</th>\n",
       "      <th>11th</th>\n",
       "      <th>12th</th>\n",
       "      <th>...</th>\n",
       "      <th>Wife</th>\n",
       "      <th>Amer-Indian-Eskimo</th>\n",
       "      <th>Asian-Pac-Islander</th>\n",
       "      <th>Black</th>\n",
       "      <th>Other</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27504 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Federal-gov   Local-gov   Private   Self-emp-inc   Self-emp-not-inc  \\\n",
       "0                 0           0         0              0                  0   \n",
       "1                 0           0         0              0                  1   \n",
       "2                 0           0         1              0                  0   \n",
       "3                 0           0         1              0                  0   \n",
       "4                 0           0         1              0                  0   \n",
       "...             ...         ...       ...            ...                ...   \n",
       "29165             0           0         1              0                  0   \n",
       "29166             0           0         1              0                  0   \n",
       "29167             0           0         1              0                  0   \n",
       "29168             0           0         1              0                  0   \n",
       "29169             0           0         0              1                  0   \n",
       "\n",
       "        State-gov   Without-pay   10th   11th   12th  ...   Wife  \\\n",
       "0               1             0      0      0      0  ...      0   \n",
       "1               0             0      0      0      0  ...      0   \n",
       "2               0             0      0      0      0  ...      0   \n",
       "3               0             0      0      1      0  ...      0   \n",
       "4               0             0      0      0      0  ...      1   \n",
       "...           ...           ...    ...    ...    ...  ...    ...   \n",
       "29165           0             0      0      0      0  ...      1   \n",
       "29166           0             0      0      0      0  ...      0   \n",
       "29167           0             0      0      0      0  ...      0   \n",
       "29168           0             0      0      0      0  ...      0   \n",
       "29169           0             0      0      0      0  ...      1   \n",
       "\n",
       "        Amer-Indian-Eskimo   Asian-Pac-Islander   Black   Other   White  \\\n",
       "0                        0                    0       0       0       1   \n",
       "1                        0                    0       0       0       1   \n",
       "2                        0                    0       0       0       1   \n",
       "3                        0                    0       1       0       0   \n",
       "4                        0                    0       0       0       1   \n",
       "...                    ...                  ...     ...     ...     ...   \n",
       "29165                    0                    0       0       0       1   \n",
       "29166                    0                    0       0       0       1   \n",
       "29167                    0                    0       0       0       1   \n",
       "29168                    0                    0       0       0       1   \n",
       "29169                    0                    0       0       0       1   \n",
       "\n",
       "        Female   Male  hours-per-week  income  \n",
       "0            0      1              40   <=50K  \n",
       "1            0      1              13   <=50K  \n",
       "2            0      1              40   <=50K  \n",
       "3            0      1              40   <=50K  \n",
       "4            1      0              40   <=50K  \n",
       "...        ...    ...             ...     ...  \n",
       "29165        1      0              38   <=50K  \n",
       "29166        0      1              40    >50K  \n",
       "29167        1      0              40   <=50K  \n",
       "29168        0      1              20   <=50K  \n",
       "29169        1      0              40    >50K  \n",
       "\n",
       "[27504 rows x 59 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(Adult_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd7341b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income\n",
      " <=50K    20509\n",
      " >50K      6995\n",
      "Name: count, dtype: int64\n",
      "income\n",
      "0    20509\n",
      "1     6995\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Turning the inputs into 1 or 0\n",
    "print (Adult_df['income'].value_counts())\n",
    "Adult_df['income'].replace([' <=50K', ' >50K'], [0,1], inplace = True)\n",
    "print (Adult_df['income'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0aed805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "   0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  0  0  0  0  1  0  1 40  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "   0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0  0  0  0  0  1  0  1 13  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1\n",
      "   0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  0  0  0  0  1  0  1 40  0]\n",
      " [ 0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0  0  0  1  0  0  0  1 40  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "   0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  1  0  0  0  0  1  1  0 40  0]]\n"
     ]
    }
   ],
   "source": [
    "Adult_np = Adult_df.values\n",
    "\n",
    "\n",
    "#Preview of the first 5 rows\n",
    "\n",
    "print(Adult_np[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "584b4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the features - set a X  and our target - set as Y\n",
    "X = Adult_np[:,:58]\n",
    "Y = Adult_np[:,58:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2323d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27504, 58)\n",
      "(27504, 1)\n",
      "[[ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  0  0  0  0  1  1  0 60  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1\n",
      "   0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  0  0  0  0  1  0  1 40  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "   0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  1  0  0  0  0  1  1  0 40  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "   0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0\n",
      "   0  0  0  0  0  0  1  0  1 50  1]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "   0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  0  0  0  0  1  1  0 40  0]]\n"
     ]
    }
   ],
   "source": [
    "X_and_Y = np.hstack((X, Y))            \n",
    "np.random.shuffle(X_and_Y)     \n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_and_Y[:5])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c459333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9168, 58)\n",
      "(9168, 1)\n",
      "(9168, 58)\n",
      "(9168, 1)\n",
      "(9168, 58)\n",
      "(9168, 1)\n"
     ]
    }
   ],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "X_shuffled_adult = X_and_Y[:,:58]\n",
    "Y_shuffled_adult = X_and_Y[:,58:]\n",
    "\n",
    "#######Check if this is correct\n",
    "X_train_adult = X_shuffled_adult[:9168,:58]     \n",
    "Y_train_adult = Y_shuffled_adult[:9168]              \n",
    "X_val_adult   = X_shuffled_adult[9168:18336,:58] \n",
    "Y_val_adult   = Y_shuffled_adult[9168:18336]           \n",
    "X_test_adult  = X_shuffled_adult[18336:,:58]   \n",
    "Y_test_adult  = Y_shuffled_adult[18336:]              \n",
    "print(X_train_adult.shape)\n",
    "print(Y_train_adult.shape)\n",
    "print(X_val_adult.shape)\n",
    "print(Y_val_adult.shape)\n",
    "print(X_test_adult.shape)\n",
    "print(Y_test_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "X_train_adult1, X_test_adult1, Y_train_adult1, Y_test_adult1 = train_test_split(X_shuffled_adult,\n",
    "                                                        Y_shuffled_adult, test_size=0.2, random_state=42)\n",
    "X_train_adult2, X_test_adult2, Y_train_adult2, Y_test_adult2 = train_test_split(X_shuffled_adult,\n",
    "                                                        Y_shuffled_adult, test_size=0.5, random_state=42)\n",
    "X_train_adult3, X_test_adult3, Y_train_adult3, Y_test_adult3 = train_test_split(X_shuffled_adult,\n",
    "                                                        Y_shuffled_adult, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46caa8",
   "metadata": {},
   "source": [
    "## Decision Tree - Adult Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b56e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_adult1, X_train_adult1, Y_test_adult1, Y_train_adult1)\n",
    "accuracy_DTAD1 = DT.accuracy\n",
    "DT_precision1 = DT.precision\n",
    "model_DTAD1 = DT.DT_model\n",
    "accuracy_tr_DTAD1 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f714e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_adult2, X_train_adult2, Y_test_adult2, Y_train_adult2)\n",
    "accuracy_DTAD2 = DT.accuracy\n",
    "DT_precision2 = DT.precision\n",
    "model_DTAD2 = DT.DT_model\n",
    "accuracy_tr_DTAD2 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_adult3, X_train_adult3, Y_test_adult3, Y_train_adult3)\n",
    "accuracy_DTAD3 = DT.accuracy\n",
    "DT_precision3 = DT.precision\n",
    "model_DTAD3 = DT.DT_model\n",
    "accuracy_tr_DTAD3 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_DTAD1 = np.average( cross_val_score(model_DTAD1, X_train_adult1, Y_train_adult1, cv=5) )\n",
    "score_DTAD2 = np.average( cross_val_score(model_DTAD2, X_train_adult1, Y_train_adult1, cv=5) )\n",
    "score_DTAD3 = np.average( cross_val_score(model_DTAD3, X_train_adult1, Y_train_adult1, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DT Test Accuracy 20/80 split:', accuracy_DTAD1)\n",
    "print('DT Test Accuracy 50/50 split:', accuracy_DTAD2)\n",
    "print('DT Test Accuracy 80/20 split:', accuracy_DTAD3)\n",
    "print('')\n",
    "print('DT Train Accuracy 20/80 split:', accuracy_tr_DTAD1)\n",
    "print('DT Train Accuracy 50/50 split:', accuracy_tr_DTAD2)\n",
    "print('DT Train Accuracy 80/20 split:', accuracy_tr_DTAD3)\n",
    "print('')\n",
    "print('DT Validation Accuracy 20/80 split:', score_DTAD1)\n",
    "print('DT Validation Accuracy 50/50 split:', score_DTAD2)\n",
    "print('DT Validation Accuracy 80/20 split:', score_DTAD3)\n",
    "print('')\n",
    "print('DT Accuracy 20/80 split:', (accuracy_DTAD1+accuracy_tr_DTAD1+score_DTAD1)/3)\n",
    "print('DT Accuracy 50/50 split:', (accuracy_DTAD2+accuracy_tr_DTAD2+score_DTAD2)/3)\n",
    "print('DT Accuracy 80/20 split:', (accuracy_DTAD3+accuracy_tr_DTAD3+score_DTAD3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1122067",
   "metadata": {},
   "source": [
    "## SVM - Adult Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5211f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_adult1, X_train_adult1, Y_test_adult1, Y_train_adult1)\n",
    "accuracy_SVMAD1 = SVM.accuracy\n",
    "SVM_precision1 = SVM.precision\n",
    "model_SVMAD1 = SVM.SVM_model\n",
    "accuracy_tr_SVMAD1 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_adult2, X_train_adult2, Y_test_adult2, Y_train_adult2)\n",
    "accuracy_SVMAD2 = SVM.accuracy\n",
    "SVM_precision2 = SVM.precision\n",
    "model_SVMAD2 = SVM.SVM_model\n",
    "accuracy_tr_SVMAD2 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77944d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_adult3, X_train_adult3, Y_test_adult3, Y_train_adult3)\n",
    "accuracy_SVMAD3 = SVM.accuracy\n",
    "SVM_precision3 = SVM.precision\n",
    "model_SVMAD3 = SVM.SVM_model\n",
    "accuracy_tr_SVMAD3 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_SVMAD1 = np.average( cross_val_score(model_SVMAD1, X_train_adult1, Y_train_adult1, cv=5) )\n",
    "score_SVMAD2 = np.average( cross_val_score(model_SVMAD2, X_train_adult2, Y_train_adult2, cv=5) )\n",
    "score_SVMAD3 = np.average( cross_val_score(model_SVMAD3, X_train_adult3, Y_train_adult3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d874ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM Test Accuracy 20/80 split:', accuracy_SVMAD1)\n",
    "print('SVM Test Accuracy 50/50 split:', accuracy_SVMAD2)\n",
    "print('SVM Test Accuracy 80/20 split:', accuracy_SVMAD3)\n",
    "print('')\n",
    "print('SVM Train Accuracy 20/80 split:', accuracy_tr_SVMAD1)\n",
    "print('SVM Train Accuracy 50/50 split:', accuracy_tr_SVMAD2)\n",
    "print('SVM Train Accuracy 80/20 split:', accuracy_tr_SVMAD3)\n",
    "print('')\n",
    "print('SVM Validation Accuracy 20/80 split:', score_SVMAD1)\n",
    "print('SVM Validation Accuracy 50/50 split:', score_SVMAD2)\n",
    "print('SVM Validation Accuracy 80/20 split:', score_SVMAD3)\n",
    "print('')\n",
    "print('SVM Accuracy 20/80 split:', (accuracy_SVMAD1+accuracy_tr_SVMAD1+score_SVMAD1)/3)\n",
    "print('SVM Accuracy 50/50 split:', (accuracy_SVMAD2+accuracy_tr_SVMAD2+score_SVMAD2)/3)\n",
    "print('SVM Accuracy 80/20 split:', (accuracy_SVMAD3+accuracy_tr_SVMAD3+score_SVMAD3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3ceac",
   "metadata": {},
   "source": [
    "## LOG - Adult Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_adult1, X_train_adult1, Y_test_adult1, Y_train_adult1)\n",
    "accuracy_logAD1 = LOG.accuracy\n",
    "precision_log1 = LOG.precision\n",
    "model_logAD1 = LOG.LOG_model\n",
    "accuracy_tr_LOGAD1 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_adult2, X_train_adult2, Y_test_adult2, Y_train_adult2)\n",
    "accuracy_logAD2 = LOG.accuracy\n",
    "precision_log2 = LOG.precision\n",
    "model_logAD2 = LOG.LOG_model\n",
    "accuracy_tr_LOGAD2 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c48a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_adult3, X_train_adult3, Y_test_adult3, Y_train_adult3)\n",
    "accuracy_logAD3 = LOG.accuracy\n",
    "precision_log3 = LOG.precision\n",
    "model_logAD3 = LOG.LOG_model\n",
    "accuracy_tr_LOGAD3 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LOGAD1 = np.average( cross_val_score(model_logAD1, X_train_adult1, Y_train_adult1, cv=5) )\n",
    "score_LOGAD2 = np.average( cross_val_score(model_logAD2, X_train_adult2, Y_train_adult2, cv=5) )\n",
    "score_LOGAD3 = np.average( cross_val_score(model_logAD3, X_train_adult3, Y_train_adult3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LOG Test Accuracy 20/80 split:', accuracy_logAD1)\n",
    "print('LOG Test Accuracy 50/50 split:', accuracy_logAD2)\n",
    "print('LOG Test Accuracy 80/20 split:', accuracy_logAD3)\n",
    "print('')\n",
    "print('LOG Train Accuracy 20/80 split:', accuracy_tr_LOG1)\n",
    "print('LOG Train Accuract 50/50 split:', accuracy_tr_LOG2)\n",
    "print('LOG Train Accuracy 80/20 split:', accuracy_tr_LOG3)\n",
    "print('')\n",
    "print('LOG Validation Accuracy 20/80 split:', score_LOGAD1)\n",
    "print('LOG Validation Accuracy 50/50 split:', score_LOGAD2)\n",
    "print('LOG Validation Accuracy 80/20 split:', score_LOGAD3)\n",
    "print('')\n",
    "print('LOG Accuracy 20/80 split:', (accuracy_logAD1+accuracy_tr_LOGAD1+score_LOGAD1)/3)\n",
    "print('LOG Accuracy 50/50 split:', (accuracy_logAD2+accuracy_tr_LOGAD2+score_LOGAD2)/3)\n",
    "print('LOG Accuracy 80/20 split:', (accuracy_logAD3+accuracy_tr_LOGAD3+score_LOGAD3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749716d9",
   "metadata": {},
   "source": [
    "## KNN - Adult Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_adult1, X_train_adult1, Y_test_adult1, Y_train_adult1)\n",
    "knn_accuracyAD1 = knn.accuracy\n",
    "knn_precision1 = knn.precision\n",
    "model_knnAD1 = knn.knn_model\n",
    "accuracy_tr_knnAD1 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_adult2, X_train_adult2, Y_test_adult2, Y_train_adult2)\n",
    "knn_accuracyAD2 = knn.accuracy\n",
    "knn_precision2 = knn.precision\n",
    "model_knnAD2 = knn.knn_model\n",
    "accuracy_tr_knnAD2 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_adult3, X_train_adult3, Y_test_adult3, Y_train_adult3)\n",
    "knn_accuracyAD3 = knn.accuracy\n",
    "knn_precision3 = knn.precision\n",
    "model_knnAD3 = knn.knn_model\n",
    "accuracy_tr_knnAD3 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_KNNAD1 = np.average( cross_val_score(model_knnAD1, X_train_adult1, Y_train_adult1, cv=5) )\n",
    "score_KNNAD2 = np.average( cross_val_score(model_knnAD2, X_train_adult2, Y_train_adult2, cv=5) )\n",
    "score_KNNAD3 = np.average( cross_val_score(model_knnAD3, X_train_adult3, Y_train_adult3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd3fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN Test Accuracy 20/80 split:', knn_accuracyAD1)\n",
    "print('KNN Test Accuracy 50/50 split:', knn_accuracyAD2)\n",
    "print('KNN Test Accuracy 80/20 split:', knn_accuracyAD3)\n",
    "print('')\n",
    "print('KNN Train Accuracy 20/80 split:', accuracy_tr_knnAD1)\n",
    "print('KNN Train Accuracy 50/50 split:', accuracy_tr_knnAD2)\n",
    "print('KNN Train Accuracy 80/20 split:', accuracy_tr_knnAD3)\n",
    "print('')\n",
    "print('KNN Validation Accuracy 20/80 split:', score_KNNAD1)\n",
    "print('KNN Validation Accuracy 50/50 split:', score_KNNAD2)\n",
    "print('KNN Validation Accuracy 80/20 split:', score_KNNAD3)\n",
    "print('')\n",
    "print('KNN Accuracy 20/80 split:', (knn_accuracyAD1+accuracy_tr_knnAD1+score_KNNAD1)/3)\n",
    "print('KNN Accuracy 50/50 split:', (knn_accuracyAD2+accuracy_tr_knnAD2+score_KNNAD2)/3)\n",
    "print('KNN Accuracy 80/20 split:', (knn_accuracyAD3+accuracy_tr_knnAD3+score_KNNAD3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d027fe",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron - Adult Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_adult1, X_train_adult1, Y_test_adult1, Y_train_adult1)\n",
    "MLP_accuracyAD1 = MLP.accuracy\n",
    "MLP_precision1 = MLP.precision\n",
    "model_mlpAD1 = MLP.MLP_model\n",
    "accuracy_tr_MLPAD1 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d479b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_adult2, X_train_adult2, Y_test_adult2, Y_train_adult2)\n",
    "MLP_accuracyAD2 = MLP.accuracy\n",
    "MLP_precision2 = MLP.precision\n",
    "model_mlpAD2 = MLP.MLP_model\n",
    "accuracy_tr_MLPAD2 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_adult3, X_train_adult3, Y_test_adult3, Y_train_adult3)\n",
    "MLP_accuracyAD3 = MLP.accuracy\n",
    "MLP_precision3 = MLP.precision\n",
    "model_mlpAD3 = MLP.MLP_model\n",
    "accuracy_tr_MLPAD3 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06360e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_MLPAD1 = np.average( cross_val_score(model_mlpAD1, X_train_adult1, Y_train_adult1, cv=5) )\n",
    "score_MLPAD2 = np.average( cross_val_score(model_mlpAD2, X_train_adult2, Y_train_adult2, cv=5) )\n",
    "score_MLPAD3 = np.average( cross_val_score(model_mlpAD3, X_train_adult3, Y_train_adult3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MLP Test Accuracy 20/80 split:', MLP_accuracyAD1)\n",
    "print('MLP Test Accuracy 50/50 split:', MLP_accuracyAD2)\n",
    "print('MLP Test Accuracy 80/20 split:', MLP_accuracyAD3)\n",
    "print('')\n",
    "print('MLP Train Accuracy 20/80 split:', accuracy_tr_MLPAD1)\n",
    "print('MLP Train Accuract 50/50 split:', accuracy_tr_MLPAD2)\n",
    "print('MLP Train Accuracy 80/20 split:', accuracy_tr_MLPAD3)\n",
    "print('')\n",
    "print('MLP Validation Accuracy 20/80 split:', score_MLPAD1)\n",
    "print('MLP Validation Accuracy 50/50 split:', score_MLPAD2)\n",
    "print('MLP Validation Accuracy 80/20 split:', score_MLPAD3)\n",
    "print('')\n",
    "print('MLP Accuracy 20/80 split:', (MLP_accuracyAD1+accuracy_tr_MLPAD1+score_MLPAD1)/3)\n",
    "print('MLP Accuracy 50/50 split:', (MLP_accuracyAD2+accuracy_tr_MLPAD2+score_MLPAD2)/3)\n",
    "print('MLP Accuracy 80/20 split:', (MLP_accuracyAD3+accuracy_tr_MLPAD3+score_MLPAD3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3936a",
   "metadata": {},
   "source": [
    "## Breast Cancer Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ebd1e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1      2      3       4       5        6        7        8   \\\n",
       "0      842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "1      842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
       "2    84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
       "3    84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..        ... ..    ...    ...     ...     ...      ...      ...      ...   \n",
       "564    926424  M  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
       "565    926682  M  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
       "566    926954  M  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
       "567    927241  M  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
       "568     92751  B   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
       "\n",
       "          9   ...      22     23      24      25       26       27      28  \\\n",
       "0    0.14710  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.07017  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.12790  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.10520  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.10430  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.13890  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.09791  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05302  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.15200  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         29      30       31  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the data frame\n",
    "BC_df = pd.read_csv('Datasets/Breast_Cancer/wdbc.data', header = None)\n",
    "BC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cdde811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the the ID\n",
    "BC_df = BC_df.drop(0, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdc966f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the columns to thier respected placed\n",
    "BC_df.columns = [ 'Diagnosis', 'radius1', 'texture1', \n",
    "              'perimeter1','area1','smoothness1', \n",
    "              'compactness1','concavity1','concave_points1',\n",
    "              'symmetry1', 'fractal_dimension1','radius2', \n",
    "              'texture2', 'perimeter2','area2',\n",
    "              'smoothness2', 'compactness2','concavity2',\n",
    "              'concave_points2','symmetry2', \n",
    "              'fractal_dimension2','radius3', \n",
    "              'texture3', 'perimeter3','area3',\n",
    "              'smoothness3', 'compactness3','concavity3',\n",
    "              'concave_points3', 'symmetry3', 'fractal_dimension3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5db11c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'B']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a list of the unique diagnosis\n",
    "BC_df['Diagnosis'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cebd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the diagnosis into 0 or 1\n",
    "print (BC_df['Diagnosis'].value_counts())\n",
    "BC_df['Diagnosis'].replace(['B', 'M'], [0,1], inplace = True)\n",
    "print (BC_df['Diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfba381",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ad291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since majority of the is a float, all of it except diagnosis got multiplied by 100 and round to turn into an int\n",
    "BC_df1 = BC_df.drop('Diagnosis', axis =1)*100\n",
    "BC_df1 = BC_df1.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC_df1 = BC_df1.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the rounded data to be paired with Diagnosis\n",
    "BC_df = pd.concat([BC_df['Diagnosis'],BC_df1], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1869a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data into a numpy array\n",
    "BC_np = BC_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5be7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "\n",
    "# Stack them together for shuffling and shuffled the data points to counter pattern recognition of the sequence\n",
    "# Obtaining the features - set a X  and our target - set as Y\n",
    "X_BC = BC_np[:,1:]\n",
    "Y_BC = BC_np[:,:1]\n",
    "X_and_YBC = np.hstack((X_BC, Y_BC))            \n",
    "np.random.shuffle(X_and_YBC)     \n",
    "\n",
    "print(X_BC.shape)\n",
    "print(Y_BC.shape)\n",
    "print(X_and_YBC[:5])  \n",
    "X_shuffledBC = X_and_YBC[:,:30]\n",
    "Y_shuffledBC = X_and_YBC[:,30:]\n",
    "\n",
    "#######Check if this is correct\n",
    "X_trainBC = X_shuffledBC[:190,:30]     \n",
    "Y_trainBC = Y_shuffledBC[:190]              \n",
    "X_valBC   = X_shuffledBC[190:380,:30] \n",
    "Y_valBC   = Y_shuffledBC[190:380]           \n",
    "X_testBC  = X_shuffledBC[380:,:30]   \n",
    "Y_testBC  = Y_shuffledBC[380:]              \n",
    "print(X_trainBC.shape)\n",
    "print(Y_trainBC.shape)\n",
    "print(X_valBC.shape)\n",
    "print(Y_valBC.shape)\n",
    "print(X_testBC.shape)\n",
    "print(Y_testBC.shape)\n",
    "Y_shuffledBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25bca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dat\n",
    "X_train_BC1, X_test_BC1, Y_train_BC1, Y_test_BC1 = train_test_split(X_shuffledBC,\n",
    "                                                        Y_shuffledBC, test_size=0.2, random_state=42)\n",
    "X_train_BC2, X_test_BC2, Y_train_BC2, Y_test_BC2 = train_test_split(X_shuffledBC,\n",
    "                                                        Y_shuffledBC, test_size=0.5, random_state=42)\n",
    "X_train_BC3, X_test_BC3, Y_train_BC3, Y_test_BC3 = train_test_split(X_shuffledBC,\n",
    "                                                        Y_shuffledBC, test_size=0.8, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c11055",
   "metadata": {},
   "source": [
    "## Decision Tree - Breast Cancer Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_BC1, X_train_BC1, Y_test_BC1, Y_train_BC1)\n",
    "accuracy_DTBC1 = DT.accuracy\n",
    "DT_precision1 = DT.precision\n",
    "model_DTBC1 = DT.DT_model\n",
    "accuracy_tr_DTBC1 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_BC2, X_train_BC2, Y_test_BC2, Y_train_BC2)\n",
    "accuracy_DTBC2 = DT.accuracy\n",
    "DT_precision2 = DT.precision\n",
    "model_DTBC2 = DT.DT_model\n",
    "accuracy_tr_DTBC2 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f72226",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_test_BC3, X_train_BC3, Y_test_BC3, Y_train_BC3)\n",
    "accuracy_DTBC3 = DT.accuracy\n",
    "DT_precision3 = DT.precision\n",
    "model_DTBC3 = DT.DT_model\n",
    "accuracy_tr_DTBC3 = DT.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_DTBC1 = np.average( cross_val_score(model_DTBC1, X_train1, Y_train1, cv=5) ) \n",
    "score_DTBC2 = np.average( cross_val_score(model_DTBC2, X_train1, Y_train1, cv=5) )\n",
    "score_DTBC3 = np.average( cross_val_score(model_DTBC3, X_train1, Y_train1, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c83143",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DT Test Accuracy 20/80 split:', accuracy_DTBC1)\n",
    "print('DT Test Accuracy 50/50 split:', accuracy_DTBC2)\n",
    "print('DT Test Accuracy 80/20 split:', accuracy_DTBC3)\n",
    "print('')\n",
    "print('DT Train Accuracy 20/80 split:', accuracy_tr_DTBC1)\n",
    "print('DT Train Accuracy 50/50 split:', accuracy_tr_DTBC2)\n",
    "print('DT Train Accuracy 80/20 split:', accuracy_tr_DTBC3)\n",
    "print('')\n",
    "print('DT Validation Accuracy 20/80 split:', score_DTBC1)\n",
    "print('DT Validation Accuracy 50/50 split:', score_DTBC2)\n",
    "print('DT Validation Accuracy 80/20 split:', score_DTBC3)\n",
    "print('')\n",
    "print('DT Accuracy 20/80 split:', (accuracy_DTBC1+accuracy_tr_DTBC1+score_DTBC1)/3)\n",
    "print('DT Accuracy 50/50 split:', (accuracy_DTBC2+accuracy_tr_DTBC2+score_DTBC2)/3)\n",
    "print('DT Accuracy 80/20 split:', (accuracy_DTBC3+accuracy_tr_DTBC3+score_DTBC3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c71a7",
   "metadata": {},
   "source": [
    "## SVM - Breast Cancer Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_BC1, X_train_BC1, Y_test_BC1, Y_train_BC1)\n",
    "accuracy_SVMBC1 = SVM.accuracy\n",
    "precision_SVM1 = SVM.precision\n",
    "model_SVMBC1 = SVM.SVM_model\n",
    "accuracy_tr_SVMBC1 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e189a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_BC2, X_train_BC2, Y_test_BC2, Y_train_BC2)\n",
    "accuracy_SVMBC2 = SVM.accuracy\n",
    "precision_SVM2 = SVM.precision\n",
    "model_SVMBC2 = SVM.SVM_model\n",
    "accuracy_tr_SVMBC2 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(X_test_BC3, X_train_BC3, Y_test_BC3, Y_train_BC3)\n",
    "accuracy_SVMBC3 = SVM.accuracy\n",
    "precision_SVM3 = SVM.precision\n",
    "model_SVMBC3 = SVM.SVM_model\n",
    "accuracy_tr_SVMBC3 = SVM.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_SVMBC1 = np.average( cross_val_score(model_SVMBC1, X_train_BC1, Y_train_BC1, cv=5) )\n",
    "score_SVMBC2 = np.average( cross_val_score(model_SVMBC2, X_train_BC2, Y_train_BC2, cv=5) )\n",
    "score_SVMBC3 = np.average( cross_val_score(model_SVMBC3, X_train_BC3, Y_train_BC3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM Test Accuracy 20/80 split:', accuracy_SVMBC1)\n",
    "print('SVM Test Accuracy 50/50 split:', accuracy_SVMBC2)\n",
    "print('SVM Test Accuracy 80/20 split:', accuracy_SVMBC3)\n",
    "print('')\n",
    "print('SVM Train Accuracy 20/80 split:', accuracy_tr_SVMBC1)\n",
    "print('SVM Train Accuracy 50/50 split:', accuracy_tr_SVMBC2)\n",
    "print('SVM Train Accuracy 80/20 split:', accuracy_tr_SVMBC3)\n",
    "print('')\n",
    "print('SVM Validation Accuracy 20/80 split:', score_SVMBC1)\n",
    "print('SVM Validation Accuracy 50/50 split:', score_SVMBC2)\n",
    "print('SVM Validation Accuracy 80/20 split:', score_SVMBC3)\n",
    "print('')\n",
    "print('SVM Accuracy 20/80 split:', (accuracy_SVMBC1+accuracy_tr_SVMBC1+score_SVMBC1)/3)\n",
    "print('SVM Accuracy 50/50 split:', (accuracy_SVMBC2+accuracy_tr_SVMBC2+score_SVMBC2)/3)\n",
    "print('SVM Accuracy 80/20 split:', (accuracy_SVMBC3+accuracy_tr_SVMBC3+score_SVMBC3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b174549",
   "metadata": {},
   "source": [
    "## LOG - Breast Cancer Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_BC1, X_train_BC1, Y_test_BC1, Y_train_BC1)\n",
    "accuracy_logBC1 = LOG.accuracy\n",
    "precision_logBC1 = LOG.precision\n",
    "model_logBC1 = LOG.LOG_model\n",
    "accuracy_tr_LOGBC1 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_BC2, X_train_BC2, Y_test_BC2, Y_train_BC2)\n",
    "accuracy_logBC2 = LOG.accuracy\n",
    "precision_logBC2 = LOG.precision\n",
    "model_logBC2 = LOG.LOG_model\n",
    "accuracy_tr_LOGBC2 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a51866",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG(X_test_BC3, X_train_BC3, Y_test_BC3, Y_train_BC3)\n",
    "accuracy_logBC3 = LOG.accuracy\n",
    "precision_logBC3 = LOG.precision\n",
    "model_logBC3 = LOG.LOG_model\n",
    "accuracy_tr_LOGBC3 = LOG.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5030da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LOGBC1 = np.average( cross_val_score(model_logBC1, X_train_BC1, Y_train_BC1, cv=5) )\n",
    "score_LOGBC2 = np.average( cross_val_score(model_logBC2, X_train_BC2, Y_train_BC2, cv=5) )\n",
    "score_LOGBC3 = np.average( cross_val_score(model_logBC3, X_train_BC3, Y_train_BC3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb342514",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LOG Test Accuracy 20/80 split:', accuracy_logBC1)\n",
    "print('LOG Test Accuracy 50/50 split:', accuracy_logBC2)\n",
    "print('LOG Test Accuracy 80/20 split:', accuracy_logBC3)\n",
    "print('')\n",
    "print('LOG Train Accuracy 20/80 split:', accuracy_tr_LOGBC1)\n",
    "print('LOG Train Accuracy 50/50 split:', accuracy_tr_LOGBC2)\n",
    "print('LOG Train Accuracy 80/20 split:', accuracy_tr_LOGBC3)\n",
    "print('')\n",
    "print('LOG Validation Accuracy 20/80 split:', score_LOGBC1)\n",
    "print('LOG Validation Accuracy 50/50 split:', score_LOGBC2)\n",
    "print('LOG Validation Accuracy 80/20 split:', score_LOGBC3)\n",
    "print('')\n",
    "print('LOG Accuracy 20/80 split:', (accuracy_logBC1+accuracy_tr_LOGBC1+score_LOGBC1)/3)\n",
    "print('LOG Accuracy 50/50 split:', (accuracy_logBC2+accuracy_tr_LOGBC2+score_LOGBC2)/3)\n",
    "print('LOG Accuracy 80/20 split:', (accuracy_logBC3+accuracy_tr_LOGBC3+score_LOGBC3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3d021",
   "metadata": {},
   "source": [
    "## KNN - Breast Cancer Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_BC1, X_train_BC1, Y_test_BC1, Y_train_BC1)\n",
    "knn_accuracyBC1 = knn.accuracy\n",
    "knn_precisionBC1 = knn.precision\n",
    "model_knnBC1 = knn.knn_model\n",
    "accuracy_tr_knnBC1 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_BC2, X_train_BC2, Y_test_BC2, Y_train_BC2)\n",
    "knn_accuracyBC2 = knn.accuracy\n",
    "knn_precisionBC2 = knn.precision\n",
    "model_knnBC2 = knn.knn_model\n",
    "accuracy_tr_knnBC2 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80013ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_test_BC3, X_train_BC3, Y_test_BC3, Y_train_BC3)\n",
    "knn_accuracyBC3 = knn.accuracy\n",
    "knn_precisionBC3 = knn.precision\n",
    "model_knnBC3 = knn.knn_model\n",
    "accuracy_tr_knnBC3 = knn.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6024790",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_KNNBC1 = np.average( cross_val_score(model_knnBC1, X_train_BC1, Y_train_BC1, cv=5) )\n",
    "score_KNNBC2 = np.average( cross_val_score(model_knnBC2, X_train_BC2, Y_train_BC2, cv=5) )\n",
    "score_KNNBC3 = np.average( cross_val_score(model_knnBC3, X_train_BC3, Y_train_BC3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN Test Accuracy 20/80 split:', knn_accuracyBC1)\n",
    "print('KNN Test Accuracy 50/50 split:', knn_accuracyBC2)\n",
    "print('KNN Test Accuracy 80/20 split:', knn_accuracyBC3)\n",
    "print('')\n",
    "print('KNN Train Accuracy 20/80 split:', accuracy_tr_knnBC1)\n",
    "print('KNN Train Accuracy 50/50 split:', accuracy_tr_knnBC2)\n",
    "print('KNN Train Accuracy 80/20 split:', accuracy_tr_knnBC3)\n",
    "print('')\n",
    "print('KNN Validation Accuracy 20/80 split:', score_KNNBC1)\n",
    "print('KNN Validation Accuracy 50/50 split:', score_KNNBC2)\n",
    "print('KNN Validation Accuracy 80/20 split:', score_KNNBC3)\n",
    "print('')\n",
    "print('KNN Accuracy 20/80 split:', (accuracy_knn1+accuracy_tr_knnBC1+score_KNNBC1)/3)\n",
    "print('KNN Accuracy 50/50 split:', (accuracy_knn2+accuracy_tr_knnBC2+score_KNNBC2)/3)\n",
    "print('KNN Accuracy 80/20 split:', (accuracy_knn3+accuracy_tr_knnBC3+score_KNNBC3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9634f18",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron - Breast Cancer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_BC1, X_train_BC1, Y_test_BC1, Y_train_BC1)\n",
    "MLP_accuracyBC1 = MLP.accuracy\n",
    "MLP_precisionBC1 = MLP.precision\n",
    "model_mlpBC1 = MLP.MLP_model\n",
    "accuracy_tr_MLPBC1 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_BC2, X_train_BC2, Y_test_BC2, Y_train_BC2)\n",
    "MLP_accuracyBC2 = MLP.accuracy\n",
    "MLP_precisionBC2 = MLP.precision\n",
    "model_mlpBC2 = MLP.MLP_model\n",
    "accuracy_tr_MLPBC2 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c889aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(X_test_BC3, X_train_BC3, Y_test_BC3, Y_train_BC3)\n",
    "MLP_accuracyBC3 = MLP.accuracy\n",
    "MLP_precisionBC3 = MLP.precision\n",
    "model_mlpBC3 = MLP.MLP_model\n",
    "accuracy_tr_MLPBC3 = MLP.accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_MLPBC1 = np.average( cross_val_score(model_mlpBC1, X_train_BC1, Y_train_BC1, cv=5) )\n",
    "score_MLPBC2 = np.average( cross_val_score(model_mlpBC2, X_train_BC2, Y_train_BC2, cv=5) )\n",
    "score_MLPBC3 = np.average( cross_val_score(model_mlpBC3, X_train_BC3, Y_train_BC3, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3dc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MLP Test Accuracy 20/80 split:', MLP_accuracyBC1)\n",
    "print('MLP Test Accuracy 50/50 split:', MLP_accuracyBC2)\n",
    "print('MLP Test Accuracy 80/20 split:', MLP_accuracyBC3)\n",
    "print('')\n",
    "print('MLP Train Accuracy 20/80 split:', accuracy_tr_MLPBC1)\n",
    "print('MLP Train Accuracy 50/50 split:', accuracy_tr_MLPBC2)\n",
    "print('MLP Train Accuracy 80/20 split:', accuracy_tr_MLPBC3)\n",
    "print('')\n",
    "print('MLP Validation Accuracy 20/80 split:', score_MLPBC1)\n",
    "print('MLP Validation Accuracy 50/50 split:', score_MLPBC2)\n",
    "print('MLP Validation Accuracy 80/20 split:', score_MLPBC3)\n",
    "print('')\n",
    "print('MLP Accuracy 20/80 split:', (MLP_accuracyBC1+accuracy_tr_MLPBC1+score_MLPBC1)/3)\n",
    "print('MLP Accuracy 50/50 split:', (MLP_accuracyBC2+accuracy_tr_MLPBC2+score_MLPBC2)/3)\n",
    "print('MLP Accuracy 80/20 split:', (MLP_accuracyBC3+accuracy_tr_MLPBC3+score_MLPBC3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cb80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0246353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df477f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5a920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614074ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1720f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f5848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb161ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ca18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa9f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
